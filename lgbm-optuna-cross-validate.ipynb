{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa826f87",
   "metadata": {},
   "source": [
    "### Lgbm and Optuna\n",
    "* changed with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b02034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# the GBM used\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# to encode categoricals\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# see utils.py\n",
    "from utils import add_features, rmsle, train_encoders, apply_encoders\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8915e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals and load train dataset\n",
    "\n",
    "FILE_TRAIN = \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce1f6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "data_orig = pd.read_csv(FILE_TRAIN)\n",
    "\n",
    "#\n",
    "# Data preparation, feature engineering\n",
    "#\n",
    "\n",
    "# add features (hour, year) extracted form timestamp\n",
    "data_extended = add_features(data_orig)\n",
    "\n",
    "# ok, we will treat as categorical: holiday, hour, season, weather, workingday, year\n",
    "all_columns = data_extended.columns\n",
    "\n",
    "# cols to be ignored\n",
    "# atemp and temp are strongly correlated (0.98) we're taking only one\n",
    "del_columns = [\"datetime\", \"casual\", \"registered\", \"temp\"]\n",
    "\n",
    "TARGET = \"count\"\n",
    "cat_cols = [\"season\", \"holiday\", \"workingday\", \"weather\", \"hour\", \"year\"]\n",
    "num_cols = list(set(all_columns) - set([TARGET]) - set(del_columns) - set(cat_cols))\n",
    "features = sorted(cat_cols + num_cols)\n",
    "\n",
    "# drop ignored columns\n",
    "data_used = data_extended.drop(del_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6223fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for coding: season \n",
      "train for coding: weather \n",
      "train for coding: year \n",
      "\n",
      "Coding: season \n",
      "Coding: weather \n",
      "Coding: year \n"
     ]
    }
   ],
   "source": [
    "# Code categorical columns (only season, weather, year)\n",
    "le_list = train_encoders(data_used)\n",
    "\n",
    "# coding\n",
    "data_used = apply_encoders(data_used, le_list)\n",
    "\n",
    "# define indexes for cat_cols\n",
    "# cat boost want indexes\n",
    "cat_columns_idxs = [i for i, col in enumerate(features) if col in cat_cols]\n",
    "\n",
    "# finally we have the train dataset\n",
    "X = data_used[features].values\n",
    "y = data_used[TARGET].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212183d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "FOLDS = 7\n",
    "SEED = 4321\n",
    "N_TRIALS = 60\n",
    "STUDY_NAME = \"gbm3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b66070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here we define what we do using Optuna\n",
    "#\n",
    "def objective(trial):\n",
    "\n",
    "    # tuning on max_depth, n_estimators for the example\n",
    "    dict_params = {\n",
    "        \"num_iterations\": trial.suggest_categorical(\n",
    "            \"num_iterations\", [3000, 4000, 5000]\n",
    "        ),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", low=1e-4, high=1e-2),\n",
    "        \"metrics\": [\"rmse\"],\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 4, 10)\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 2 ** (max_depth), 2 ** (max_depth))\n",
    "\n",
    "    dict_params[\"max_depth\"] = max_depth\n",
    "    dict_params[\"num_leaves\"] = num_leaves\n",
    "\n",
    "    regr = lgb.LGBMRegressor(**dict_params)\n",
    "\n",
    "    # using rmsle for scoring\n",
    "    scorer = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "    scores = cross_validate(regr, X, y, cv=FOLDS, scoring=scorer)\n",
    "\n",
    "    avg_test_score = round(np.mean(scores[\"test_score\"]), 4)\n",
    "\n",
    "    return avg_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeec9af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-09 20:42:40,270]\u001b[0m A new study created in memory with name: gbm3\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:44:55,393]\u001b[0m Trial 0 finished with value: -1.2306 and parameters: {'num_iterations': 3000, 'learning_rate': 0.00022491643627371854, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 0 with value: -1.2306.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:45:29,737]\u001b[0m Trial 1 finished with value: -0.5385 and parameters: {'num_iterations': 3000, 'learning_rate': 0.008243270372124339, 'max_depth': 8, 'num_leaves': 256}. Best is trial 1 with value: -0.5385.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:46:04,867]\u001b[0m Trial 2 finished with value: -1.1615 and parameters: {'num_iterations': 4000, 'learning_rate': 0.00023139298087528442, 'max_depth': 6, 'num_leaves': 64}. Best is trial 1 with value: -0.5385.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:49:03,362]\u001b[0m Trial 3 finished with value: -1.1785 and parameters: {'num_iterations': 4000, 'learning_rate': 0.00020015343211910778, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 1 with value: -0.5385.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:49:22,350]\u001b[0m Trial 4 finished with value: -0.6807 and parameters: {'num_iterations': 5000, 'learning_rate': 0.0011156142054857291, 'max_depth': 4, 'num_leaves': 16}. Best is trial 1 with value: -0.5385.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:50:16,364]\u001b[0m Trial 5 finished with value: -0.542 and parameters: {'num_iterations': 5000, 'learning_rate': 0.005901898001212448, 'max_depth': 8, 'num_leaves': 256}. Best is trial 1 with value: -0.5385.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:51:11,408]\u001b[0m Trial 6 finished with value: -0.5062 and parameters: {'num_iterations': 3000, 'learning_rate': 0.004024666549806875, 'max_depth': 9, 'num_leaves': 512}. Best is trial 6 with value: -0.5062.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:51:48,646]\u001b[0m Trial 7 finished with value: -0.5549 and parameters: {'num_iterations': 5000, 'learning_rate': 0.001940412445467772, 'max_depth': 6, 'num_leaves': 64}. Best is trial 6 with value: -0.5062.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:52:05,679]\u001b[0m Trial 8 finished with value: -0.8959 and parameters: {'num_iterations': 3000, 'learning_rate': 0.0005973362715882451, 'max_depth': 5, 'num_leaves': 32}. Best is trial 6 with value: -0.5062.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:53:14,649]\u001b[0m Trial 9 finished with value: -0.5568 and parameters: {'num_iterations': 5000, 'learning_rate': 0.0072925335168540426, 'max_depth': 9, 'num_leaves': 512}. Best is trial 6 with value: -0.5062.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:54:02,241]\u001b[0m Trial 10 finished with value: -0.4787 and parameters: {'num_iterations': 3000, 'learning_rate': 0.002652951860944835, 'max_depth': 8, 'num_leaves': 256}. Best is trial 10 with value: -0.4787.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:54:48,084]\u001b[0m Trial 11 finished with value: -0.481 and parameters: {'num_iterations': 3000, 'learning_rate': 0.002860230344872689, 'max_depth': 8, 'num_leaves': 256}. Best is trial 10 with value: -0.4787.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:55:21,724]\u001b[0m Trial 12 finished with value: -0.4823 and parameters: {'num_iterations': 3000, 'learning_rate': 0.002535585787568677, 'max_depth': 7, 'num_leaves': 128}. Best is trial 10 with value: -0.4787.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:56:21,535]\u001b[0m Trial 13 finished with value: -0.5912 and parameters: {'num_iterations': 3000, 'learning_rate': 0.000953502011116508, 'max_depth': 8, 'num_leaves': 256}. Best is trial 10 with value: -0.4787.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:56:54,479]\u001b[0m Trial 14 finished with value: -0.4871 and parameters: {'num_iterations': 3000, 'learning_rate': 0.0026899009251232977, 'max_depth': 7, 'num_leaves': 128}. Best is trial 10 with value: -0.4787.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:58:16,777]\u001b[0m Trial 15 finished with value: -0.4716 and parameters: {'num_iterations': 3000, 'learning_rate': 0.0013830815651114576, 'max_depth': 9, 'num_leaves': 512}. Best is trial 15 with value: -0.4716.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:00:18,309]\u001b[0m Trial 16 finished with value: -0.8844 and parameters: {'num_iterations': 4000, 'learning_rate': 0.00040726721514756903, 'max_depth': 9, 'num_leaves': 512}. Best is trial 15 with value: -0.4716.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:02:26,152]\u001b[0m Trial 17 finished with value: -0.6904 and parameters: {'num_iterations': 3000, 'learning_rate': 0.0007837389449491916, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 15 with value: -0.4716.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:03:47,001]\u001b[0m Trial 18 finished with value: -0.4588 and parameters: {'num_iterations': 3000, 'learning_rate': 0.001511983985205884, 'max_depth': 9, 'num_leaves': 512}. Best is trial 18 with value: -0.4588.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:05:31,029]\u001b[0m Trial 19 finished with value: -0.4583 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0012766361950913752, 'max_depth': 9, 'num_leaves': 512}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:08:29,566]\u001b[0m Trial 20 finished with value: -1.3362 and parameters: {'num_iterations': 4000, 'learning_rate': 0.00010896313897307498, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:10:06,966]\u001b[0m Trial 21 finished with value: -0.4676 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0014862958012318867, 'max_depth': 9, 'num_leaves': 512}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:11:42,939]\u001b[0m Trial 22 finished with value: -0.4688 and parameters: {'num_iterations': 4000, 'learning_rate': 0.001551752612444459, 'max_depth': 9, 'num_leaves': 512}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:13:42,089]\u001b[0m Trial 23 finished with value: -0.7586 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0005160814242384663, 'max_depth': 9, 'num_leaves': 512}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:16:07,004]\u001b[0m Trial 24 finished with value: -0.4587 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0013928620353867984, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:18:58,335]\u001b[0m Trial 25 finished with value: -0.63 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0006617981230790431, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:21:40,079]\u001b[0m Trial 26 finished with value: -0.4926 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0009491279733329204, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:22:16,976]\u001b[0m Trial 27 finished with value: -0.5184 and parameters: {'num_iterations': 4000, 'learning_rate': 0.004450404489811235, 'max_depth': 7, 'num_leaves': 128}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:24:22,046]\u001b[0m Trial 28 finished with value: -0.4771 and parameters: {'num_iterations': 4000, 'learning_rate': 0.001978069466460025, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:27:20,824]\u001b[0m Trial 29 finished with value: -0.8914 and parameters: {'num_iterations': 4000, 'learning_rate': 0.00040103427371679227, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:27:54,317]\u001b[0m Trial 30 finished with value: -0.5876 and parameters: {'num_iterations': 5000, 'learning_rate': 0.0038595548020354422, 'max_depth': 6, 'num_leaves': 64}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:29:32,816]\u001b[0m Trial 31 finished with value: -0.4648 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0014612012714190505, 'max_depth': 9, 'num_leaves': 512}. Best is trial 19 with value: -0.4583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:31:18,642]\u001b[0m Trial 32 finished with value: -0.4551 and parameters: {'num_iterations': 4000, 'learning_rate': 0.001214554022260763, 'max_depth': 9, 'num_leaves': 512}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:32:32,655]\u001b[0m Trial 33 finished with value: -0.4637 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0011654478503466748, 'max_depth': 8, 'num_leaves': 256}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:33:35,889]\u001b[0m Trial 34 finished with value: -0.4751 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0018932187652574923, 'max_depth': 8, 'num_leaves': 256}. Best is trial 32 with value: -0.4551.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-09 21:36:21,682]\u001b[0m Trial 35 finished with value: -0.5614 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0007705635481575268, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:38:11,335]\u001b[0m Trial 36 finished with value: -0.4668 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0010684052370007874, 'max_depth': 9, 'num_leaves': 512}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:41:08,568]\u001b[0m Trial 37 finished with value: -1.0091 and parameters: {'num_iterations': 4000, 'learning_rate': 0.00031186471147232167, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:41:27,120]\u001b[0m Trial 38 finished with value: -0.6645 and parameters: {'num_iterations': 5000, 'learning_rate': 0.0021862618043088557, 'max_depth': 4, 'num_leaves': 16}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:43:20,597]\u001b[0m Trial 39 finished with value: -0.5266 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0008395253315355152, 'max_depth': 9, 'num_leaves': 512}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:43:36,293]\u001b[0m Trial 40 finished with value: -0.6147 and parameters: {'num_iterations': 3000, 'learning_rate': 0.00355988239592385, 'max_depth': 5, 'num_leaves': 32}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:44:49,956]\u001b[0m Trial 41 finished with value: -0.4622 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0012136120752217342, 'max_depth': 8, 'num_leaves': 256}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:46:03,442]\u001b[0m Trial 42 finished with value: -0.4625 and parameters: {'num_iterations': 4000, 'learning_rate': 0.001214051599053362, 'max_depth': 8, 'num_leaves': 256}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:47:11,420]\u001b[0m Trial 43 finished with value: -0.4725 and parameters: {'num_iterations': 4000, 'learning_rate': 0.001623305658747423, 'max_depth': 8, 'num_leaves': 256}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:49:37,017]\u001b[0m Trial 44 finished with value: -0.6004 and parameters: {'num_iterations': 5000, 'learning_rate': 0.0005613341671344897, 'max_depth': 9, 'num_leaves': 512}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:50:41,875]\u001b[0m Trial 45 finished with value: -0.4774 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0018259166625719493, 'max_depth': 8, 'num_leaves': 256}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:51:21,209]\u001b[0m Trial 46 finished with value: -0.5034 and parameters: {'num_iterations': 3000, 'learning_rate': 0.0012645390490185371, 'max_depth': 7, 'num_leaves': 128}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:52:33,235]\u001b[0m Trial 47 finished with value: -0.5088 and parameters: {'num_iterations': 4000, 'learning_rate': 0.003176532638048739, 'max_depth': 9, 'num_leaves': 512}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:53:24,655]\u001b[0m Trial 48 finished with value: -0.5143 and parameters: {'num_iterations': 3000, 'learning_rate': 0.00504919897921027, 'max_depth': 9, 'num_leaves': 512}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:54:14,681]\u001b[0m Trial 49 finished with value: -0.4946 and parameters: {'num_iterations': 5000, 'learning_rate': 0.0023252453681691433, 'max_depth': 7, 'num_leaves': 128}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:55:32,470]\u001b[0m Trial 50 finished with value: -0.484 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0009648052911081686, 'max_depth': 8, 'num_leaves': 256}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:56:46,067]\u001b[0m Trial 51 finished with value: -0.4616 and parameters: {'num_iterations': 4000, 'learning_rate': 0.001242291786918444, 'max_depth': 8, 'num_leaves': 256}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:57:39,224]\u001b[0m Trial 52 finished with value: -0.5999 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0007188596464105025, 'max_depth': 7, 'num_leaves': 128}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 21:59:11,130]\u001b[0m Trial 53 finished with value: -0.4739 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0016831277678531727, 'max_depth': 9, 'num_leaves': 512}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 22:00:23,503]\u001b[0m Trial 54 finished with value: -0.4609 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0012744632840314912, 'max_depth': 8, 'num_leaves': 256}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 22:01:22,031]\u001b[0m Trial 55 finished with value: -0.6047 and parameters: {'num_iterations': 3000, 'learning_rate': 0.0009272829104969998, 'max_depth': 8, 'num_leaves': 256}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 22:02:44,617]\u001b[0m Trial 56 finished with value: -0.4874 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0021749910729823765, 'max_depth': 9, 'num_leaves': 512}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 22:04:55,385]\u001b[0m Trial 57 finished with value: -0.8101 and parameters: {'num_iterations': 3000, 'learning_rate': 0.0006262792714338394, 'max_depth': 10, 'num_leaves': 1024}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 22:06:33,776]\u001b[0m Trial 58 finished with value: -0.461 and parameters: {'num_iterations': 4000, 'learning_rate': 0.0014342738377378164, 'max_depth': 9, 'num_leaves': 512}. Best is trial 32 with value: -0.4551.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 22:07:26,853]\u001b[0m Trial 59 finished with value: -0.5545 and parameters: {'num_iterations': 4000, 'learning_rate': 0.009852133978673286, 'max_depth': 9, 'num_leaves': 512}. Best is trial 32 with value: -0.4551.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# launch Optuna Study\n",
    "study = optuna.create_study(study_name=STUDY_NAME, direction=\"maximize\")\n",
    "\n",
    "study.optimize(objective, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1803c5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_iterations': 4000,\n",
       " 'learning_rate': 0.001214554022260763,\n",
       " 'max_depth': 9,\n",
       " 'num_leaves': 512}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2b2274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_num_iterations</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>-0.4551</td>\n",
       "      <td>2022-03-09 21:29:32.818017</td>\n",
       "      <td>2022-03-09 21:31:18.642596</td>\n",
       "      <td>0 days 00:01:45.824579</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>9</td>\n",
       "      <td>4000</td>\n",
       "      <td>512</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.4583</td>\n",
       "      <td>2022-03-09 21:03:47.002722</td>\n",
       "      <td>2022-03-09 21:05:31.029041</td>\n",
       "      <td>0 days 00:01:44.026319</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>9</td>\n",
       "      <td>4000</td>\n",
       "      <td>512</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.4587</td>\n",
       "      <td>2022-03-09 21:13:42.090333</td>\n",
       "      <td>2022-03-09 21:16:07.003726</td>\n",
       "      <td>0 days 00:02:24.913393</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>10</td>\n",
       "      <td>4000</td>\n",
       "      <td>1024</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.4588</td>\n",
       "      <td>2022-03-09 21:02:26.153530</td>\n",
       "      <td>2022-03-09 21:03:47.000883</td>\n",
       "      <td>0 days 00:01:20.847353</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>9</td>\n",
       "      <td>3000</td>\n",
       "      <td>512</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>-0.4609</td>\n",
       "      <td>2022-03-09 21:59:11.131690</td>\n",
       "      <td>2022-03-09 22:00:23.502942</td>\n",
       "      <td>0 days 00:01:12.371252</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>8</td>\n",
       "      <td>4000</td>\n",
       "      <td>256</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number   value             datetime_start          datetime_complete  \\\n",
       "32      32 -0.4551 2022-03-09 21:29:32.818017 2022-03-09 21:31:18.642596   \n",
       "19      19 -0.4583 2022-03-09 21:03:47.002722 2022-03-09 21:05:31.029041   \n",
       "24      24 -0.4587 2022-03-09 21:13:42.090333 2022-03-09 21:16:07.003726   \n",
       "18      18 -0.4588 2022-03-09 21:02:26.153530 2022-03-09 21:03:47.000883   \n",
       "54      54 -0.4609 2022-03-09 21:59:11.131690 2022-03-09 22:00:23.502942   \n",
       "\n",
       "                 duration  params_learning_rate  params_max_depth  \\\n",
       "32 0 days 00:01:45.824579              0.001215                 9   \n",
       "19 0 days 00:01:44.026319              0.001277                 9   \n",
       "24 0 days 00:02:24.913393              0.001393                10   \n",
       "18 0 days 00:01:20.847353              0.001512                 9   \n",
       "54 0 days 00:01:12.371252              0.001274                 8   \n",
       "\n",
       "    params_num_iterations  params_num_leaves     state  \n",
       "32                   4000                512  COMPLETE  \n",
       "19                   4000                512  COMPLETE  \n",
       "24                   4000               1024  COMPLETE  \n",
       "18                   3000                512  COMPLETE  \n",
       "54                   4000                256  COMPLETE  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize trials as an ordered Pandas df\n",
    "df = study.trials_dataframe()\n",
    "\n",
    "result_df = df[df[\"state\"] == \"COMPLETE\"].sort_values(by=[\"value\"], ascending=False)\n",
    "\n",
    "# best on top\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5932a",
   "metadata": {},
   "source": [
    "### train the model on entire train set and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0251fefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 152 ms, total: 1min 2s\n",
      "Wall time: 15.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(learning_rate=0.001214554022260763, max_depth=9,\n",
       "              num_iterations=4000, num_leaves=512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# maybe I shoud add save best model (see nu_iteration in cell below)\n",
    "model = lgb.LGBMRegressor(**study.best_params)\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e72d394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f46b363e2b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = \"lgboost.txt\"\n",
    "\n",
    "model.booster_.save_model(model_file, num_iteration=study.best_params[\"num_iterations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bcd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
