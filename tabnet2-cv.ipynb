{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0929beed",
   "metadata": {},
   "source": [
    "### pytorch-tabnet\n",
    "* 5 fold cv\n",
    "* best result for single model alg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab1086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2860754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "FIGSIZE = (9, 6)\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "FILE_TRAIN = \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633b1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = pd.read_csv(FILE_TRAIN)\n",
    "\n",
    "# feature engineering\n",
    "data_orig['datetime'] = pd.to_datetime(data_orig['datetime'])\n",
    "\n",
    "# this way I add 3 engineered features\n",
    "data_orig['hour'] = data_orig['datetime'].dt.hour\n",
    "\n",
    "# mese di fatto è duplicato di season. rimuovo\n",
    "#data_orig['month'] = data_orig['datetime'].dt.month\n",
    "# data_orig['day'] = data_orig['datetime'].dt.day\n",
    "data_orig['year'] = data_orig['datetime'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20381e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutte le colonne: 14\n",
      "Colonne ignorate: 4\n",
      "target: 1\n",
      "Colonne cat: 6\n",
      "Colonne num: 3\n",
      "Num. features 9\n"
     ]
    }
   ],
   "source": [
    "all_columns = data_orig.columns\n",
    "\n",
    "# colonne da ignorare\n",
    "# atemp and temp are strongly correlated (0.98) taking only one\n",
    "del_columns = ['datetime', 'casual', 'registered', 'temp']\n",
    "\n",
    "TARGET = \"count\"\n",
    "\n",
    "cat_cols = ['season', 'holiday','workingday', 'weather', 'hour', 'year']\n",
    "\n",
    "num_cols = list(set(all_columns) - set([TARGET]) - set(del_columns) - set(cat_cols))\n",
    "\n",
    "features = sorted(cat_cols + num_cols)\n",
    "\n",
    "print('Tutte le colonne:', len(all_columns))\n",
    "print('Colonne ignorate:', len(del_columns))\n",
    "print('target:', len([TARGET]))\n",
    "print('Colonne cat:', len(cat_cols))\n",
    "print('Colonne num:', len(num_cols))\n",
    "print('Num. features', len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d96d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_used = data_orig.drop(del_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf02deb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season 4 [1 2 3 4]\n",
      "holiday 2 [0 1]\n",
      "workingday 2 [0 1]\n",
      "weather 4 [1 2 3 4]\n",
      "hour 24 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "year 2 [2011 2012]\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = cat_cols\n",
    "categorical_dims =  {}\n",
    "vet_lenc = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(col, data_used[col].nunique(), data_used[col].unique())\n",
    "    l_enc = LabelEncoder()\n",
    "    data_used[col] = l_enc.fit_transform(data_used[col].values)\n",
    "    vet_lenc.append(l_enc)\n",
    "    categorical_dims[col] = len(l_enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9249c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88772eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing fold: 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 64915.54318| val_0_rmse: 207.72345| val_0_rmsle: 3.33527 |  0:00:00s\n",
      "epoch 50 | loss: 3398.20264| val_0_rmse: 55.69292| val_0_rmsle: 0.32845 |  0:00:47s\n",
      "epoch 100| loss: 2923.74165| val_0_rmse: 59.0454 | val_0_rmsle: 0.30486 |  0:01:35s\n",
      "epoch 150| loss: 3126.23728| val_0_rmse: 54.4858 | val_0_rmsle: 0.42791 |  0:02:21s\n",
      "epoch 200| loss: 2352.15818| val_0_rmse: 50.90203| val_0_rmsle: 0.27902 |  0:03:09s\n",
      "epoch 250| loss: 2164.53267| val_0_rmse: 49.10467| val_0_rmsle: 0.26385 |  0:03:57s\n",
      "epoch 300| loss: 2100.76719| val_0_rmse: 48.56569| val_0_rmsle: 0.25323 |  0:04:44s\n",
      "epoch 350| loss: 1951.568| val_0_rmse: 48.71729| val_0_rmsle: 0.27985 |  0:05:31s\n",
      "epoch 400| loss: 2008.18462| val_0_rmse: 46.48582| val_0_rmsle: 0.21245 |  0:06:18s\n",
      "epoch 450| loss: 1850.84148| val_0_rmse: 57.4932 | val_0_rmsle: 0.33263 |  0:07:07s\n",
      "\n",
      "Early stopping occurred at epoch 495 with best_epoch = 395 and best_val_0_rmsle = 0.21042\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Processing fold: 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 65490.02518| val_0_rmse: 209.28231| val_0_rmsle: 3.15504 |  0:00:00s\n",
      "epoch 50 | loss: 3338.29324| val_0_rmse: 57.90754| val_0_rmsle: 0.32251 |  0:00:47s\n",
      "epoch 100| loss: 2930.56932| val_0_rmse: 50.56883| val_0_rmsle: 0.3008  |  0:01:34s\n",
      "epoch 150| loss: 2500.20383| val_0_rmse: 51.94657| val_0_rmsle: 0.42469 |  0:02:21s\n",
      "epoch 200| loss: 2265.10746| val_0_rmse: 51.93382| val_0_rmsle: 0.28514 |  0:03:09s\n",
      "epoch 250| loss: 2138.00042| val_0_rmse: 48.42867| val_0_rmsle: 0.33309 |  0:03:55s\n",
      "epoch 300| loss: 2363.93151| val_0_rmse: 49.93301| val_0_rmsle: 0.33922 |  0:04:43s\n",
      "epoch 350| loss: 2031.88765| val_0_rmse: 47.35087| val_0_rmsle: 0.29435 |  0:05:30s\n",
      "epoch 400| loss: 2104.35198| val_0_rmse: 47.79971| val_0_rmsle: 0.25444 |  0:06:17s\n",
      "\n",
      "Early stopping occurred at epoch 439 with best_epoch = 339 and best_val_0_rmsle = 0.22517\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Processing fold: 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 65268.67639| val_0_rmse: 233.56142| val_0_rmsle: 3.65177 |  0:00:00s\n",
      "epoch 50 | loss: 3457.34626| val_0_rmse: 87.25911| val_0_rmsle: 0.41188 |  0:00:48s\n",
      "epoch 100| loss: 2830.64788| val_0_rmse: 59.51289| val_0_rmsle: 0.30363 |  0:01:35s\n",
      "epoch 150| loss: 2482.88305| val_0_rmse: 52.43214| val_0_rmsle: 0.2502  |  0:02:22s\n",
      "epoch 200| loss: 2265.05824| val_0_rmse: 57.07536| val_0_rmsle: 0.26348 |  0:03:09s\n",
      "\n",
      "Early stopping occurred at epoch 214 with best_epoch = 114 and best_val_0_rmsle = 0.20709\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Processing fold: 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 63821.00645| val_0_rmse: 246.33597| val_0_rmsle: 4.60049 |  0:00:00s\n",
      "epoch 50 | loss: 3604.1165| val_0_rmse: 56.38249| val_0_rmsle: 0.27631 |  0:00:48s\n",
      "epoch 100| loss: 3224.97783| val_0_rmse: 61.26462| val_0_rmsle: 0.25811 |  0:01:37s\n",
      "epoch 150| loss: 2640.55755| val_0_rmse: 55.51237| val_0_rmsle: 0.26216 |  0:02:23s\n",
      "epoch 200| loss: 2361.59736| val_0_rmse: 53.7249 | val_0_rmsle: 0.25766 |  0:03:10s\n",
      "epoch 250| loss: 2283.23699| val_0_rmse: 56.56032| val_0_rmsle: 0.25281 |  0:03:57s\n",
      "epoch 300| loss: 2377.52464| val_0_rmse: 74.72037| val_0_rmsle: 0.23106 |  0:04:44s\n",
      "epoch 350| loss: 2110.26848| val_0_rmse: 55.54951| val_0_rmsle: 0.34478 |  0:05:31s\n",
      "epoch 400| loss: 1966.42969| val_0_rmse: 54.41357| val_0_rmsle: 0.25256 |  0:06:18s\n",
      "epoch 450| loss: 1969.2033| val_0_rmse: 52.95561| val_0_rmsle: 0.28209 |  0:07:05s\n",
      "epoch 500| loss: 1872.78378| val_0_rmse: 52.12199| val_0_rmsle: 0.20636 |  0:07:52s\n",
      "epoch 550| loss: 1803.78015| val_0_rmse: 53.07182| val_0_rmsle: 0.21533 |  0:08:40s\n",
      "\n",
      "Early stopping occurred at epoch 559 with best_epoch = 459 and best_val_0_rmsle = 0.20499\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Processing fold: 5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 64904.11161| val_0_rmse: 230.95597| val_0_rmsle: 3.50604 |  0:00:00s\n",
      "epoch 50 | loss: 3091.14864| val_0_rmse: 54.24871| val_0_rmsle: 0.33025 |  0:00:48s\n",
      "epoch 100| loss: 2873.37116| val_0_rmse: 55.99597| val_0_rmsle: 0.30792 |  0:01:37s\n",
      "epoch 150| loss: 2700.49608| val_0_rmse: 56.45645| val_0_rmsle: 0.37195 |  0:02:24s\n",
      "epoch 200| loss: 2579.73503| val_0_rmse: 53.58268| val_0_rmsle: 0.24937 |  0:03:11s\n",
      "epoch 250| loss: 2241.33609| val_0_rmse: 53.18236| val_0_rmsle: 0.24974 |  0:03:58s\n",
      "epoch 300| loss: 2196.01992| val_0_rmse: 53.82794| val_0_rmsle: 0.29949 |  0:04:46s\n",
      "epoch 350| loss: 2023.51319| val_0_rmse: 49.0101 | val_0_rmsle: 0.25904 |  0:05:33s\n",
      "epoch 400| loss: 2053.91638| val_0_rmse: 51.1632 | val_0_rmsle: 0.28956 |  0:06:20s\n",
      "epoch 450| loss: 1910.81443| val_0_rmse: 50.0848 | val_0_rmsle: 0.35202 |  0:07:07s\n",
      "epoch 500| loss: 1931.96564| val_0_rmse: 49.19805| val_0_rmsle: 0.27664 |  0:07:56s\n",
      "epoch 550| loss: 1831.31575| val_0_rmse: 54.99131| val_0_rmsle: 0.29171 |  0:08:44s\n",
      "epoch 600| loss: 1819.8856| val_0_rmse: 49.20061| val_0_rmsle: 0.26569 |  0:09:31s\n",
      "\n",
      "Early stopping occurred at epoch 642 with best_epoch = 542 and best_val_0_rmsle = 0.22643\n",
      "Best weights from best epoch are automatically used!\n",
      "CPU times: user 36min 38s, sys: 8.7 s, total: 36min 46s\n",
      "Wall time: 37min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "FOLDS = 5\n",
    "\n",
    "skf = KFold(n_splits = FOLDS, shuffle=True, random_state = SEED)\n",
    "\n",
    "params = {'n_steps':2,\n",
    "          'cat_dims':cat_dims,\n",
    "          'cat_idxs':cat_idxs,\n",
    "          'verbose':50\n",
    "         }\n",
    "\n",
    "best_models = []\n",
    "\n",
    "i = 1\n",
    "for train_idx, valid_idx in skf.split(data_used):\n",
    "    print()\n",
    "    print('Processing fold:', i)\n",
    "    \n",
    "    data_train = data_used.iloc[train_idx]\n",
    "    data_valid = data_used.iloc[valid_idx]\n",
    "    \n",
    "    x_train = data_train[features].values\n",
    "    y_train = data_train[TARGET].values\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "    x_valid = data_valid[features].values\n",
    "    y_valid = data_valid[TARGET].values\n",
    "    y_valid = y_valid.reshape(-1, 1)\n",
    "    \n",
    "    # clf = TabNetRegressor(n_steps = 2, cat_dims=cat_dims, cat_idxs=cat_idxs, verbose=50)\n",
    "    model = TabNetRegressor(**params)\n",
    "\n",
    "    # provo a cercare rmsle\n",
    "    model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric=['rmse', 'rmsle'], max_epochs=1000, patience=100, batch_size=256)\n",
    "    \n",
    "    best_models.append(model)\n",
    "    \n",
    "    # next iteration\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e877a",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2f4383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbce7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add engineered features\n",
    "# feature engineering\n",
    "test_orig['datetime'] = pd.to_datetime(test_orig['datetime'])\n",
    "\n",
    "# this way I add 3 engineered features\n",
    "test_orig['hour'] = test_orig['datetime'].dt.hour\n",
    "#test_orig['month'] = test_orig['datetime'].dt.month\n",
    "# test_orig['day'] = test_orig['datetime'].dt.day\n",
    "test_orig['year'] = test_orig['datetime'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81210d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season 4 [1 2 3 4]\n",
      "holiday 2 [0 1]\n",
      "workingday 2 [1 0]\n",
      "weather 4 [1 2 3 4]\n",
      "hour 24 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "year 2 [2011 2012]\n"
     ]
    }
   ],
   "source": [
    "# code categorical\n",
    "for i, col in enumerate(cat_cols):\n",
    "    print(col, test_orig[col].nunique(), test_orig[col].unique())\n",
    "    l_enc = vet_lenc[i]\n",
    "    test_orig[col] = l_enc.transform(test_orig[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1f91246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions from model 1\n",
      "\n",
      "Predictions from model 2\n",
      "\n",
      "Predictions from model 3\n",
      "\n",
      "Predictions from model 4\n",
      "\n",
      "Predictions from model 5\n"
     ]
    }
   ],
   "source": [
    "x_test = test_orig[features].values\n",
    "\n",
    "avg_score = np.zeros((x_test.shape[0], 1))\n",
    "                     \n",
    "i = 0\n",
    "for model in best_models:\n",
    "    print()\n",
    "    print('Predictions from model', i+1)\n",
    "    \n",
    "    score_test = model.predict(x_test)\n",
    "    \n",
    "    avg_score += score_test/float(FOLDS)\n",
    "                     \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64d91352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3eb81639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[\"count\"] = avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72146353",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = df_sub[\"count\"] < 0\n",
    "\n",
    "df_sub.loc[condition, \"count\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fc772e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_SUB = \"submission33.csv\"\n",
    "\n",
    "df_sub.to_csv(FILE_SUB, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9542980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 244k/244k [00:01<00:00, 149kB/s]\n",
      "Successfully submitted to Bike Sharing Demand"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c \"bike-sharing-demand\" -f $FILE_SUB -m \"sub33 tabnet cv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07f4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch110_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch110_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
