{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa826f87",
   "metadata": {},
   "source": [
    "### Lgbm and Optuna\n",
    "* changed with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b02034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# the GBM used\n",
    "mport xgboost as xgb\n",
    "import catboost as cat\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# to encode categoricals\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# see utils.py\n",
    "from utils import add_features, rmsle, train_encoders, apply_encoders \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8915e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals and load train dataset\n",
    "\n",
    "FILE_TRAIN = \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce1f6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "data_orig = pd.read_csv(FILE_TRAIN)\n",
    "\n",
    "#\n",
    "# Data preparation, feature engineering\n",
    "#\n",
    "\n",
    "# add features (hour, year) extracted form timestamp\n",
    "data_extended = add_features(data_orig)\n",
    "\n",
    "# ok, we will treat as categorical: holiday, hour, season, weather, workingday, year\n",
    "all_columns = data_extended.columns\n",
    "\n",
    "# cols to be ignored\n",
    "# atemp and temp are strongly correlated (0.98) we're taking only one\n",
    "del_columns = ['datetime', 'casual', 'registered', 'temp']\n",
    "\n",
    "TARGET = \"count\"\n",
    "cat_cols = ['season', 'holiday','workingday', 'weather', 'hour', 'year']\n",
    "num_cols = list(set(all_columns) - set([TARGET]) - set(del_columns) - set(cat_cols))\n",
    "features = sorted(cat_cols + num_cols)\n",
    "\n",
    "# drop ignored columns\n",
    "data_used = data_extended.drop(del_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6223fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns: 14\n",
      "Ignored columns: 4\n",
      "Target: 1\n",
      "Categorical columns: 7\n",
      "Numerical columns: 2\n",
      "All the features 9\n"
     ]
    }
   ],
   "source": [
    "# Code categorical columns (only season, weather, year)\n",
    "le_list = train_encoders(data_used)\n",
    "\n",
    "# coding\n",
    "data_used = apply_encoders(data_used, le_list)\n",
    "\n",
    "# define indexes for cat_cols\n",
    "# cat boost want indexes\n",
    "cat_columns_idxs = [i for i, col in enumerate(features) if col in cat_cols]\n",
    "\n",
    "# finally we have the train dataset\n",
    "X = data_used[features].values\n",
    "y = data_used[TARGET].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "212183d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "FOLDS = 5\n",
    "SEED = 4321\n",
    "N_TRIALS = 5\n",
    "STUDY_NAME = \"gbm3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54b66070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here we define what we do using Optuna\n",
    "#\n",
    "def objective(trial):\n",
    "    \n",
    "    # tuning on max_depth, n_estimators for the example\n",
    "    dict_params = {\n",
    "        \"num_iterations\": trial.suggest_categorical(\"num_iterations\", [3000, 4000, 5000]),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", low=1e-4, high=1e-2),\n",
    "        \"metrics\" : [\"rmse\"],\n",
    "        \"verbose\" : -1,\n",
    "    }\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 4, 10)\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 2**(max_depth), 2**(max_depth))\n",
    "    \n",
    "    dict_params['max_depth'] = max_depth\n",
    "    dict_params['num_leaves'] = num_leaves\n",
    "    \n",
    "    regr = lgb.LGBMRegressor(**dict_params)\n",
    "    \n",
    "    # using rmsle for scoring\n",
    "    scorer = make_scorer(rmsle, greater_is_better=False)\n",
    "    \n",
    "    scores = cross_validate(regr, X, y, cv=FOLDS, scoring=scorer)\n",
    "    \n",
    "    avg_test_score = round(np.mean(scores['test_score']), 4)\n",
    "        \n",
    "    return avg_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeec9af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-09 11:44:08,014]\u001b[0m A new study created in memory with name: gbm3\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 11:44:53,441]\u001b[0m Trial 0 finished with value: -1.3121 and parameters: {'num_iterations': 3000, 'learning_rate': 0.00017125621912421937, 'max_depth': 8, 'num_leaves': 256}. Best is trial 0 with value: -1.3121.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 11:45:18,176]\u001b[0m Trial 1 finished with value: -1.3638 and parameters: {'num_iterations': 4000, 'learning_rate': 0.00010698031788920725, 'max_depth': 6, 'num_leaves': 64}. Best is trial 0 with value: -1.3121.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 11:45:41,954]\u001b[0m Trial 2 finished with value: -0.5258 and parameters: {'num_iterations': 5000, 'learning_rate': 0.0034648547200920796, 'max_depth': 6, 'num_leaves': 64}. Best is trial 2 with value: -0.5258.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 11:47:29,543]\u001b[0m Trial 3 finished with value: -1.2259 and parameters: {'num_iterations': 5000, 'learning_rate': 0.000141646290605655, 'max_depth': 9, 'num_leaves': 512}. Best is trial 2 with value: -0.5258.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 11:47:49,915]\u001b[0m Trial 4 finished with value: -1.3099 and parameters: {'num_iterations': 5000, 'learning_rate': 0.00011586165697773894, 'max_depth': 5, 'num_leaves': 32}. Best is trial 2 with value: -0.5258.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# launch Optuna Study\n",
    "study = optuna.create_study(study_name=STUDY_NAME, direction=\"maximize\")\n",
    "\n",
    "study.optimize(objective, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1803c5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_iterations': 5000,\n",
       " 'learning_rate': 0.0034648547200920796,\n",
       " 'max_depth': 6,\n",
       " 'num_leaves': 64}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae2b2274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_num_iterations</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.5258</td>\n",
       "      <td>2022-03-09 11:45:18.178690</td>\n",
       "      <td>2022-03-09 11:45:41.954595</td>\n",
       "      <td>0 days 00:00:23.775905</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "      <td>64</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.2259</td>\n",
       "      <td>2022-03-09 11:45:41.957671</td>\n",
       "      <td>2022-03-09 11:47:29.543232</td>\n",
       "      <td>0 days 00:01:47.585561</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>9</td>\n",
       "      <td>5000</td>\n",
       "      <td>512</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.3099</td>\n",
       "      <td>2022-03-09 11:47:29.546341</td>\n",
       "      <td>2022-03-09 11:47:49.915313</td>\n",
       "      <td>0 days 00:00:20.368972</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>5</td>\n",
       "      <td>5000</td>\n",
       "      <td>32</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.3121</td>\n",
       "      <td>2022-03-09 11:44:08.017368</td>\n",
       "      <td>2022-03-09 11:44:53.441192</td>\n",
       "      <td>0 days 00:00:45.423824</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>8</td>\n",
       "      <td>3000</td>\n",
       "      <td>256</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.3638</td>\n",
       "      <td>2022-03-09 11:44:53.444319</td>\n",
       "      <td>2022-03-09 11:45:18.175618</td>\n",
       "      <td>0 days 00:00:24.731299</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>6</td>\n",
       "      <td>4000</td>\n",
       "      <td>64</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number   value             datetime_start          datetime_complete  \\\n",
       "2       2 -0.5258 2022-03-09 11:45:18.178690 2022-03-09 11:45:41.954595   \n",
       "3       3 -1.2259 2022-03-09 11:45:41.957671 2022-03-09 11:47:29.543232   \n",
       "4       4 -1.3099 2022-03-09 11:47:29.546341 2022-03-09 11:47:49.915313   \n",
       "0       0 -1.3121 2022-03-09 11:44:08.017368 2022-03-09 11:44:53.441192   \n",
       "1       1 -1.3638 2022-03-09 11:44:53.444319 2022-03-09 11:45:18.175618   \n",
       "\n",
       "                duration  params_learning_rate  params_max_depth  \\\n",
       "2 0 days 00:00:23.775905              0.003465                 6   \n",
       "3 0 days 00:01:47.585561              0.000142                 9   \n",
       "4 0 days 00:00:20.368972              0.000116                 5   \n",
       "0 0 days 00:00:45.423824              0.000171                 8   \n",
       "1 0 days 00:00:24.731299              0.000107                 6   \n",
       "\n",
       "   params_num_iterations  params_num_leaves     state  \n",
       "2                   5000                 64  COMPLETE  \n",
       "3                   5000                512  COMPLETE  \n",
       "4                   5000                 32  COMPLETE  \n",
       "0                   3000                256  COMPLETE  \n",
       "1                   4000                 64  COMPLETE  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize trials as an ordered Pandas df\n",
    "df = study.trials_dataframe()\n",
    "\n",
    "result_df = df[df['state'] == 'COMPLETE'].sort_values(by=['value'], ascending=False)\n",
    "\n",
    "# best on top\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5932a",
   "metadata": {},
   "source": [
    "### train the model on entire train set and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0251fefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.6 s, sys: 67.9 ms, total: 18.7 s\n",
      "Wall time: 4.71 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(learning_rate=0.0034648547200920796, max_depth=6,\n",
       "              num_iterations=5000, num_leaves=64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# maybe I shoud add save best model (see nu_iteration in cell below)\n",
    "model = lgb.LGBMRegressor(**study.best_params)\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"lgboost.txt\"\n",
    "\n",
    "model.booster_.save_model(model_file, num_iteration=study.best_params['num_iterations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bcd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
