{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa826f87",
   "metadata": {},
   "source": [
    "### LightGBM + ADSTuner\n",
    "* two models, one for causal and the other one for registerd\n",
    "* added feature engineering\n",
    "* added year, removed temp\n",
    "* removing day I got the best results. (The range of days in the train set don't match with test set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b02034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# to use ADSTuner\n",
    "from ads.hpo.search_cv import ADSTuner\n",
    "from ads.hpo.stopping_criterion import *\n",
    "from ads.hpo.distributions import *\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# see utils.py\n",
    "from utils import add_features, rmsle, train_encoders, apply_encoders \n",
    "from utils import show_tuner_results, show_categoricals\n",
    "\n",
    "# set seaborn look&feel\n",
    "sns.set()\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8915e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals and load train dataset\n",
    "\n",
    "# number of folds for K-fold cv in ADSTuner\n",
    "FOLDS = 5\n",
    "\n",
    "# in secs\n",
    "TIME_BUDGET = 7200\n",
    "\n",
    "FILE_TRAIN = \"train.csv\"\n",
    "FILE_TEST = \"test.csv\"\n",
    "\n",
    "# train dataset\n",
    "data_orig = pd.read_csv(FILE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# add features\n",
    "#\n",
    "data_extended = add_features(data_orig)\n",
    "\n",
    "# have a look\n",
    "data_extended.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give a better look at cols with low cardinality\n",
    "# to decide which one we want to treat as categoricals\n",
    "\n",
    "# in utils.py\n",
    "# THR = 100\n",
    "show_categoricals(data_extended, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d915ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, we will treat as categorical: holiday, hour, season, weather, workingday, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6223fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = data_extended.columns\n",
    "\n",
    "# cols to be ignored\n",
    "# atemp and temp are strongly correlated (0.98) we're taking only one\n",
    "del_columns = ['datetime', 'temp']\n",
    "\n",
    "# drop ignored columns\n",
    "data_used = data_extended.drop(del_columns, axis=1)\n",
    "\n",
    "# let's code categorical\n",
    "# windspeed need a special treatment\n",
    "le_list = train_encoders(data_used)\n",
    "\n",
    "# coding\n",
    "data_used = apply_encoders(data_used, le_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90329ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['season', 'holiday','workingday', 'weather', 'hour', 'year']\n",
    "num_cols = ['atemp', 'humidity', 'windspeed']\n",
    "target_columns = ['casual', 'registered', 'count']\n",
    "features = sorted(cat_cols + num_cols)\n",
    "\n",
    "# define indexes for cat_cols\n",
    "# cat boost want indexes\n",
    "cat_columns_idxs = [i for i, col in enumerate(features) if col in cat_cols]\n",
    "\n",
    "print('All columns:', len(all_columns))\n",
    "print('Ignored columns:', len(del_columns))\n",
    "print('Categorical columns:', len(cat_cols))\n",
    "print('Numerical columns:', len(num_cols))\n",
    "print(f'All targets: {len(target_columns)}')\n",
    "print('All the features', len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c97648",
   "metadata": {},
   "source": [
    "### ADSTuner session: first model, target = registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32702a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'registered'\n",
    "\n",
    "#\n",
    "# Here we define the strategy, the space for hyper-parameters we want to explore\n",
    "#\n",
    "params = {'n_estimators': CategoricalDistribution([1000, 2000, 3000, 4000, 5000]),\n",
    "          'learning_rate': LogUniformDistribution(low=1e-5, high=1e-2),\n",
    "          'max_depth': IntUniformDistribution(5, 10),\n",
    "          'use_best_model': True,\n",
    "          'categorical_feature' : cat_columns_idxs,\n",
    "         }\n",
    "\n",
    "alg_reg = lgb.LGBMRegressor()\n",
    "\n",
    "# define the scorer function for ADSTuner, see def for rmsle before\n",
    "scorer = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "# per lista scorer sorted(sklearn.metrics.SCORERS.keys())\n",
    "tuner = ADSTuner(alg_reg, cv=FOLDS, strategy=params, scoring=scorer, study_name=\"study1\")\n",
    "\n",
    "x_train = data_used[features]\n",
    "y_train = data_used[TARGET]\n",
    "\n",
    "tuner.tune(x_train, y_train, exit_criterion=[TimeBudget(TIME_BUDGET)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the status to see if completed\n",
    "tuner.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ec27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tuner_results(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724856e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look only at completed trials, sorted with best on top. Metric chosen is in the value col.\n",
    "result_df = tuner.trials[tuner.trials['state'] == 'COMPLETE'].sort_values(by=['value'], ascending=False)\n",
    "\n",
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train the model with chosen parameters\n",
    "model1 = lgb.LGBMRegressor(**tuner.best_params)\n",
    "\n",
    "model1.fit(x_train, y_train, categorical_feature=cat_columns_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7bd9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving the model best params\n",
    "tuner.best_params\n",
    "\n",
    "with open(\"model1.pkl\", \"wb\") as mode1_file:\n",
    "    pickle.dump(tuner.best_params, mode1_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605c58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
