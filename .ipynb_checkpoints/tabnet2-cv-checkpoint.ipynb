{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d61a694",
   "metadata": {},
   "source": [
    "### pytorch-tabnet\n",
    "* 5 fold cv\n",
    "* best result for single model alg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1879b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5851108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "FIGSIZE = (9, 6)\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "FILE_TRAIN = \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7d408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for adding features\n",
    "def add_features(df):\n",
    "    new_df = df.copy()\n",
    "    new_df['datetime'] = pd.to_datetime(new_df['datetime'])\n",
    "\n",
    "    # this way I add 3 engineered features\n",
    "    new_df['hour'] = new_df['datetime'].dt.hour\n",
    "    new_df['year'] = new_df['datetime'].dt.year\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3ce89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig = pd.read_csv(FILE_TRAIN)\n",
    "\n",
    "# feature engineering\n",
    "data_added = add_features(data_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = data_orig.columns\n",
    "\n",
    "# colonne da ignorare\n",
    "# atemp and temp are strongly correlated (0.98) taking only one\n",
    "del_columns = ['datetime', 'casual', 'registered', 'temp']\n",
    "\n",
    "TARGET = \"count\"\n",
    "\n",
    "cat_cols = ['season', 'holiday','workingday', 'weather', 'hour', 'year']\n",
    "\n",
    "num_cols = list(set(all_columns) - set([TARGET]) - set(del_columns) - set(cat_cols))\n",
    "\n",
    "features = sorted(cat_cols + num_cols)\n",
    "\n",
    "print('Tutte le colonne:', len(all_columns))\n",
    "print('Colonne ignorate:', len(del_columns))\n",
    "print('target:', len([TARGET]))\n",
    "print('Colonne cat:', len(cat_cols))\n",
    "print('Colonne num:', len(num_cols))\n",
    "print('Num. features', len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce37cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_used = data_orig.drop(del_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is required for TabNet\n",
    "# categorical_columns = cat_cols\n",
    "categorical_dims =  {}\n",
    "# save label encoder for predictions\n",
    "vet_lenc = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    # print(col, data_used[col].nunique(), data_used[col].unique())\n",
    "    print(col)\n",
    "    l_enc = LabelEncoder()\n",
    "    data_used[col] = l_enc.fit_transform(data_used[col].values)\n",
    "    vet_lenc.append(l_enc)\n",
    "    categorical_dims[col] = len(l_enc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_idxs = [ i for i, f in enumerate(features) if f in cat_cols]\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in cat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18731ac8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ede8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "FOLDS = 7\n",
    "\n",
    "skf = KFold(n_splits = FOLDS, shuffle=True, random_state = SEED)\n",
    "\n",
    "# provato sembra meglio n_steps = 2\n",
    "# forse perch√® va in overfitting\n",
    "params = {'n_steps':2,\n",
    "          'cat_dims':cat_dims,\n",
    "          'cat_idxs':cat_idxs,\n",
    "          'verbose':50\n",
    "         }\n",
    "\n",
    "# we will save here all the results from FOLDS\n",
    "best_models = []\n",
    "\n",
    "EPOCHS = 1000\n",
    "PATIENCE = 100\n",
    "\n",
    "i = 1\n",
    "for train_idx, valid_idx in skf.split(data_used):\n",
    "    print()\n",
    "    print('Processing fold:', i)\n",
    "    \n",
    "    data_train = data_used.iloc[train_idx]\n",
    "    data_valid = data_used.iloc[valid_idx]\n",
    "    \n",
    "    x_train = data_train[features].values\n",
    "    y_train = data_train[TARGET].values\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "    x_valid = data_valid[features].values\n",
    "    y_valid = data_valid[TARGET].values\n",
    "    y_valid = y_valid.reshape(-1, 1)\n",
    "    \n",
    "    model = TabNetRegressor(**params)\n",
    "\n",
    "    # provo a cercare direttamente best su rmsle\n",
    "    model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric=['rmse', 'rmsle'], \n",
    "              max_epochs=EPOCHS, patience=PATIENCE, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    best_models.append(model)\n",
    "    \n",
    "    # next iteration\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278160d",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272982f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add engineered features\n",
    "test_orig = add_features(test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code categorical\n",
    "for i, col in enumerate(cat_cols):\n",
    "    print(col)\n",
    "    l_enc = vet_lenc[i]\n",
    "    test_orig[col] = l_enc.transform(test_orig[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554dfca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_orig[features].values\n",
    "\n",
    "avg_score = np.zeros((x_test.shape[0], 1))\n",
    "                     \n",
    "for i,model in enumerate(best_models):\n",
    "    print()\n",
    "    print('Predictions from model', i+1)\n",
    "    \n",
    "    score_test = model.predict(x_test)\n",
    "    \n",
    "    avg_score += score_test/float(FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e220b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[\"count\"] = avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71aad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace negative with zero\n",
    "condition = df_sub[\"count\"] < 0\n",
    "\n",
    "df_sub.loc[condition, \"count\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef13a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_SUB = \"submission33bis.csv\"\n",
    "\n",
    "df_sub.to_csv(FILE_SUB, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce9e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c \"bike-sharing-demand\" -f $FILE_SUB -m \"sub33bis tabnet cv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c4407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch110_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch110_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
