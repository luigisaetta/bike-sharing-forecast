{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa826f87",
   "metadata": {},
   "source": [
    "### Catboost and Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b02034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# the GBM used\n",
    "import catboost as cat\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# to encode categoricals\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# see utils.py\n",
    "from utils import add_features, rmsle, train_encoders, apply_encoders\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8915e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals and load train dataset\n",
    "\n",
    "FILE_TRAIN = \"train.csv\"\n",
    "FILE_TEST = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce1f6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "data_orig = pd.read_csv(FILE_TRAIN)\n",
    "\n",
    "#\n",
    "# add features: hour, year\n",
    "#\n",
    "data_extended = add_features(data_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d915ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, we will treat as categorical: holiday, hour, season, weather, workingday, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6223fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns: 14\n",
      "Ignored columns: 4\n",
      "Target: 1\n",
      "Categorical columns: 7\n",
      "Numerical columns: 2\n",
      "All the features 9\n"
     ]
    }
   ],
   "source": [
    "all_columns = data_extended.columns\n",
    "\n",
    "# cols to be ignored\n",
    "# atemp and temp are strongly correlated (0.98) we're taking only one\n",
    "del_columns = [\"datetime\", \"casual\", \"registered\", \"temp\"]\n",
    "\n",
    "TARGET = \"count\"\n",
    "cat_cols = [\"season\", \"holiday\", \"workingday\", \"weather\", \"windspeed\", \"hour\", \"year\"]\n",
    "num_cols = list(set(all_columns) - set([TARGET]) - set(del_columns) - set(cat_cols))\n",
    "features = sorted(cat_cols + num_cols)\n",
    "\n",
    "print(\"All columns:\", len(all_columns))\n",
    "print(\"Ignored columns:\", len(del_columns))\n",
    "print(\"Target:\", len([TARGET]))\n",
    "print(\"Categorical columns:\", len(cat_cols))\n",
    "print(\"Numerical columns:\", len(num_cols))\n",
    "print(\"All the features\", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90329ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop ignored columns\n",
    "data_used = data_extended.drop(del_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad0f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for coding: season \n",
      "train for coding: weather \n",
      "train for coding: year \n",
      "\n",
      "Coding: season \n",
      "Coding: weather \n",
      "Coding: year \n"
     ]
    }
   ],
   "source": [
    "# let's code categorical\n",
    "le_list = train_encoders(data_used)\n",
    "\n",
    "# coding\n",
    "data_used = apply_encoders(data_used, le_list)\n",
    "\n",
    "# define indexes for cat_cols\n",
    "# cat boost want indexes\n",
    "cat_columns_idxs = [i for i, col in enumerate(features) if col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212183d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "FOLDS = 5\n",
    "SEED = 4321\n",
    "N_TRIALS = 20\n",
    "STUDY_NAME = \"gbm1\"\n",
    "\n",
    "X = data_used[features].values\n",
    "y = data_used[TARGET].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e9a3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for CatBoost\n",
    "\n",
    "dtrain = cat.Pool(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b66070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here we define what we do using Optuna\n",
    "#\n",
    "def objective(trial):\n",
    "\n",
    "    # tuning on max_depth, n_estimators for the example\n",
    "    dict_params = {\n",
    "        \"iterations\": trial.suggest_categorical(\n",
    "            \"num_boost_round\", [1000, 2000, 3000, 4000, 5000]\n",
    "        ),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", low=1e-4, high=1e-2),\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"verbose\": 0,\n",
    "    }\n",
    "\n",
    "    history = cat.cv(\n",
    "        params=dict_params,\n",
    "        dtrain=dtrain,\n",
    "        nfold=FOLDS,\n",
    "        seed=SEED,\n",
    "        logging_level=\"Silent\",\n",
    "    )\n",
    "\n",
    "    # take the last\n",
    "    rmse = round(history[\"test-RMSE-mean\"].values[-1], 4)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeec9af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-07 19:59:57,634]\u001b[0m A new study created in memory with name: gbm1\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:00:08,447]\u001b[0m Trial 0 finished with value: 62.2979 and parameters: {'num_boost_round': 1000, 'learning_rate': 0.0028818196420147815, 'depth': 8}. Best is trial 0 with value: 62.2979.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:00:58,729]\u001b[0m Trial 1 finished with value: 50.4127 and parameters: {'num_boost_round': 3000, 'learning_rate': 0.0012954249062606673, 'depth': 10}. Best is trial 1 with value: 50.4127.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:01:05,213]\u001b[0m Trial 2 finished with value: 65.3869 and parameters: {'num_boost_round': 1000, 'learning_rate': 0.008175166890944857, 'depth': 4}. Best is trial 1 with value: 50.4127.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:01:14,483]\u001b[0m Trial 3 finished with value: 47.645 and parameters: {'num_boost_round': 1000, 'learning_rate': 0.008786405077997652, 'depth': 7}. Best is trial 3 with value: 47.645.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:01:40,797]\u001b[0m Trial 4 finished with value: 55.8223 and parameters: {'num_boost_round': 2000, 'learning_rate': 0.0016313346169615443, 'depth': 9}. Best is trial 3 with value: 47.645.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:02:23,842]\u001b[0m Trial 5 finished with value: 42.7924 and parameters: {'num_boost_round': 4000, 'learning_rate': 0.003982206973829683, 'depth': 8}. Best is trial 5 with value: 42.7924.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:02:59,211]\u001b[0m Trial 6 finished with value: 53.5404 and parameters: {'num_boost_round': 5000, 'learning_rate': 0.002021835683383219, 'depth': 5}. Best is trial 5 with value: 42.7924.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:03:14,885]\u001b[0m Trial 7 finished with value: 144.9279 and parameters: {'num_boost_round': 2000, 'learning_rate': 0.00045253886703822523, 'depth': 6}. Best is trial 5 with value: 42.7924.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:03:21,306]\u001b[0m Trial 8 finished with value: 62.411 and parameters: {'num_boost_round': 1000, 'learning_rate': 0.009430693146941898, 'depth': 4}. Best is trial 5 with value: 42.7924.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:03:40,344]\u001b[0m Trial 9 finished with value: 103.4219 and parameters: {'num_boost_round': 3000, 'learning_rate': 0.0007797827583705825, 'depth': 4}. Best is trial 5 with value: 42.7924.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:04:21,944]\u001b[0m Trial 10 finished with value: 163.0102 and parameters: {'num_boost_round': 4000, 'learning_rate': 0.00016325610692775677, 'depth': 8}. Best is trial 5 with value: 42.7924.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:04:58,173]\u001b[0m Trial 11 finished with value: 43.9876 and parameters: {'num_boost_round': 4000, 'learning_rate': 0.004137331948242886, 'depth': 7}. Best is trial 5 with value: 42.7924.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:05:34,560]\u001b[0m Trial 12 finished with value: 43.9738 and parameters: {'num_boost_round': 4000, 'learning_rate': 0.0040927720288754235, 'depth': 7}. Best is trial 5 with value: 42.7924.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:06:17,445]\u001b[0m Trial 13 finished with value: 42.89 and parameters: {'num_boost_round': 4000, 'learning_rate': 0.003815807322622072, 'depth': 8}. Best is trial 5 with value: 42.7924.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:07:10,384]\u001b[0m Trial 14 finished with value: 41.6883 and parameters: {'num_boost_round': 4000, 'learning_rate': 0.004261976914062414, 'depth': 9}. Best is trial 14 with value: 41.6883.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:08:16,648]\u001b[0m Trial 15 finished with value: 59.6391 and parameters: {'num_boost_round': 4000, 'learning_rate': 0.0006752729946809553, 'depth': 10}. Best is trial 14 with value: 41.6883.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:09:20,752]\u001b[0m Trial 16 finished with value: 94.3205 and parameters: {'num_boost_round': 5000, 'learning_rate': 0.0003056858599889464, 'depth': 9}. Best is trial 14 with value: 41.6883.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:10:13,915]\u001b[0m Trial 17 finished with value: 40.908 and parameters: {'num_boost_round': 4000, 'learning_rate': 0.006597596232345983, 'depth': 9}. Best is trial 17 with value: 40.908.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:11:03,645]\u001b[0m Trial 18 finished with value: 193.1402 and parameters: {'num_boost_round': 4000, 'learning_rate': 0.00010101268346012096, 'depth': 9}. Best is trial 17 with value: 40.908.\u001b[0m\n",
      "\u001b[32m[I 2022-03-07 20:12:12,708]\u001b[0m Trial 19 finished with value: 40.5446 and parameters: {'num_boost_round': 4000, 'learning_rate': 0.005853153235859197, 'depth': 10}. Best is trial 19 with value: 40.5446.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# launch Optuna Study\n",
    "study = optuna.create_study(study_name=STUDY_NAME, direction=\"minimize\")\n",
    "\n",
    "study.optimize(objective, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1803c5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_boost_round': 4000, 'learning_rate': 0.005853153235859197, 'depth': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3ee40e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_depth</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_num_boost_round</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>40.5446</td>\n",
       "      <td>2022-03-07 20:11:03.646640</td>\n",
       "      <td>2022-03-07 20:12:12.708702</td>\n",
       "      <td>0 days 00:01:09.062062</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>4000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>40.9080</td>\n",
       "      <td>2022-03-07 20:09:20.753132</td>\n",
       "      <td>2022-03-07 20:10:13.914972</td>\n",
       "      <td>0 days 00:00:53.161840</td>\n",
       "      <td>9</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>4000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>41.6883</td>\n",
       "      <td>2022-03-07 20:06:17.446093</td>\n",
       "      <td>2022-03-07 20:07:10.383730</td>\n",
       "      <td>0 days 00:00:52.937637</td>\n",
       "      <td>9</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>4000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>42.7924</td>\n",
       "      <td>2022-03-07 20:01:40.797935</td>\n",
       "      <td>2022-03-07 20:02:23.841957</td>\n",
       "      <td>0 days 00:00:43.044022</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>4000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>42.8900</td>\n",
       "      <td>2022-03-07 20:05:34.561573</td>\n",
       "      <td>2022-03-07 20:06:17.445085</td>\n",
       "      <td>0 days 00:00:42.883512</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>4000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number    value             datetime_start          datetime_complete  \\\n",
       "19      19  40.5446 2022-03-07 20:11:03.646640 2022-03-07 20:12:12.708702   \n",
       "17      17  40.9080 2022-03-07 20:09:20.753132 2022-03-07 20:10:13.914972   \n",
       "14      14  41.6883 2022-03-07 20:06:17.446093 2022-03-07 20:07:10.383730   \n",
       "5        5  42.7924 2022-03-07 20:01:40.797935 2022-03-07 20:02:23.841957   \n",
       "13      13  42.8900 2022-03-07 20:05:34.561573 2022-03-07 20:06:17.445085   \n",
       "\n",
       "                 duration  params_depth  params_learning_rate  \\\n",
       "19 0 days 00:01:09.062062            10              0.005853   \n",
       "17 0 days 00:00:53.161840             9              0.006598   \n",
       "14 0 days 00:00:52.937637             9              0.004262   \n",
       "5  0 days 00:00:43.044022             8              0.003982   \n",
       "13 0 days 00:00:42.883512             8              0.003816   \n",
       "\n",
       "    params_num_boost_round     state  \n",
       "19                    4000  COMPLETE  \n",
       "17                    4000  COMPLETE  \n",
       "14                    4000  COMPLETE  \n",
       "5                     4000  COMPLETE  \n",
       "13                    4000  COMPLETE  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize trials as an ordered Pandas df\n",
    "df = study.trials_dataframe()\n",
    "\n",
    "result_df = df[df[\"state\"] == \"COMPLETE\"].sort_values(by=[\"value\"], ascending=True)\n",
    "\n",
    "# best on top\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26463b8",
   "metadata": {},
   "source": [
    "### estimate RMSLE\n",
    "* it is the metric used in Kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e21101e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold: 1\n",
      "Processing fold: 2\n",
      "Processing fold: 3\n",
      "Processing fold: 4\n",
      "Processing fold: 5\n",
      "\n",
      "Avg. RMSLE: 0.4018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make an estimation of rmsle on entire dataset\n",
    "\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "avg_rmsle = 0.0\n",
    "\n",
    "#\n",
    "# at each iteration you get a different set of indexes\n",
    "# from which you get different samples for train and validation dataset\n",
    "#\n",
    "for i, (train_idx, valid_idx) in enumerate(kf.split(data_used)):\n",
    "    print(\"Processing fold:\", i + 1)\n",
    "\n",
    "    # here we split the DataFrame, using the indexes for the fold\n",
    "    data_train = data_used.iloc[train_idx]\n",
    "    data_valid = data_used.iloc[valid_idx]\n",
    "\n",
    "    x_train = data_train[features].values\n",
    "    y_train = data_train[TARGET].values\n",
    "    x_valid = data_valid[features].values\n",
    "    y_valid = data_valid[TARGET].values\n",
    "\n",
    "    model = cat.CatBoostRegressor(**study.best_params)\n",
    "\n",
    "    model.fit(x_train, y_train, silent=True)\n",
    "\n",
    "    y_valid_preds = model.predict(x_valid)\n",
    "\n",
    "    # clip to zero (to avoid nan for rmsle)\n",
    "    y_valid_preds = np.where(y_valid_preds >= 0, y_valid_preds, 0)\n",
    "\n",
    "    avg_rmsle += rmsle(y_valid_preds, y_valid) / float(FOLDS)\n",
    "\n",
    "print()\n",
    "print(\"Avg. RMSLE:\", round(avg_rmsle, 4))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5932a",
   "metadata": {},
   "source": [
    "### Train the model on entire train set and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0251fefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.5 s, sys: 4.78 s, total: 52.3 s\n",
      "Wall time: 15.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f9c8865dbe0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cat.CatBoostRegressor(**study.best_params)\n",
    "\n",
    "model.fit(x_train, y_train, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e72d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"catboost.cbm\"\n",
    "\n",
    "model.save_model(model_file, format=\"cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b35be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
