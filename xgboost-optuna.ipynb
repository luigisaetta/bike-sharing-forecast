{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa826f87",
   "metadata": {},
   "source": [
    "### XGBoost and Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b02034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# the GBM used\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# to encode categoricals\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# see utils.py\n",
    "from utils import add_features, rmsle, train_encoders, apply_encoders\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8915e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals and load train dataset\n",
    "\n",
    "FILE_TRAIN = \"train.csv\"\n",
    "FILE_TEST = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce1f6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "data_orig = pd.read_csv(FILE_TRAIN)\n",
    "\n",
    "#\n",
    "# add features\n",
    "#\n",
    "data_extended = add_features(data_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d915ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, we will treat as categorical: holiday, hour, season, weather, workingday, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6223fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns: 14\n",
      "Ignored columns: 4\n",
      "Target: 1\n",
      "Categorical columns: 7\n",
      "Numerical columns: 2\n",
      "All the features 9\n"
     ]
    }
   ],
   "source": [
    "all_columns = data_extended.columns\n",
    "\n",
    "# cols to be ignored\n",
    "# atemp and temp are strongly correlated (0.98) we're taking only one\n",
    "del_columns = [\"datetime\", \"casual\", \"registered\", \"temp\"]\n",
    "\n",
    "TARGET = \"count\"\n",
    "cat_cols = [\"season\", \"holiday\", \"workingday\", \"weather\", \"windspeed\", \"hour\", \"year\"]\n",
    "num_cols = list(set(all_columns) - set([TARGET]) - set(del_columns) - set(cat_cols))\n",
    "features = sorted(cat_cols + num_cols)\n",
    "\n",
    "print(\"All columns:\", len(all_columns))\n",
    "print(\"Ignored columns:\", len(del_columns))\n",
    "print(\"Target:\", len([TARGET]))\n",
    "print(\"Categorical columns:\", len(cat_cols))\n",
    "print(\"Numerical columns:\", len(num_cols))\n",
    "print(\"All the features\", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90329ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop ignored columns\n",
    "data_used = data_extended.drop(del_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad0f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for coding: season \n",
      "train for coding: weather \n",
      "train for coding: year \n",
      "\n",
      "Coding: season \n",
      "Coding: weather \n",
      "Coding: year \n"
     ]
    }
   ],
   "source": [
    "# let's code categorical\n",
    "le_list = train_encoders(data_used)\n",
    "\n",
    "# coding\n",
    "data_used = apply_encoders(data_used, le_list)\n",
    "\n",
    "# define indexes for cat_cols\n",
    "# cat boost want indexes\n",
    "cat_columns_idxs = [i for i, col in enumerate(features) if col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212183d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "FOLDS = 7\n",
    "SEED = 4321\n",
    "# train for longer, see if I can reduce RMSLE from 0.7\n",
    "N_TRIALS = 60\n",
    "STUDY_NAME = \"gbm2\"\n",
    "\n",
    "\n",
    "X = data_used[features].values\n",
    "y = data_used[TARGET].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "731eab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for XGBoost\n",
    "\n",
    "dtrain = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b66070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here we define what we do using Optuna\n",
    "#\n",
    "def objective(trial):\n",
    "\n",
    "    # tuning on max_depth, n_estimators for the example\n",
    "    dict_params = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", low=1e-4, high=1e-2),\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10),\n",
    "    }\n",
    "\n",
    "    # needed only for XGBoost\n",
    "    n_rounds = trial.suggest_categorical(\n",
    "        \"num_boost_round\", [1000, 2000, 3000, 4000, 5000]\n",
    "    )\n",
    "    dict_params[\"num_boost_round\"] = n_rounds\n",
    "\n",
    "    history = xgb.cv(\n",
    "        params=dict_params,\n",
    "        dtrain=dtrain,\n",
    "        nfold=FOLDS,\n",
    "        seed=SEED,\n",
    "        # as far as I see we need this for XGBoost\n",
    "        num_boost_round=n_rounds,\n",
    "    )\n",
    "\n",
    "    # take the last\n",
    "    rmse = round(history[\"test-rmse-mean\"].values[-1], 4)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeec9af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 17:09:17,851]\u001b[0m A new study created in memory with name: gbm2\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:11:13,476]\u001b[0m Trial 0 finished with value: 50.3394 and parameters: {'learning_rate': 0.001338134232361574, 'max_depth': 10, 'num_boost_round': 2000}. Best is trial 0 with value: 50.3394.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:13:29,968]\u001b[0m Trial 1 finished with value: 43.3153 and parameters: {'learning_rate': 0.0035008245434434105, 'max_depth': 6, 'num_boost_round': 5000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:16:44,695]\u001b[0m Trial 2 finished with value: 74.0092 and parameters: {'learning_rate': 0.00041053116341917425, 'max_depth': 9, 'num_boost_round': 4000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:18:27,477]\u001b[0m Trial 3 finished with value: 81.1703 and parameters: {'learning_rate': 0.0005458897213907421, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:19:01,876]\u001b[0m Trial 4 finished with value: 67.5695 and parameters: {'learning_rate': 0.002089996778149659, 'max_depth': 7, 'num_boost_round': 1000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:19:29,508]\u001b[0m Trial 5 finished with value: 219.2211 and parameters: {'learning_rate': 0.0002218244368956882, 'max_depth': 6, 'num_boost_round': 1000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:22:12,370]\u001b[0m Trial 6 finished with value: 155.6313 and parameters: {'learning_rate': 0.00015252196656444195, 'max_depth': 8, 'num_boost_round': 4000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:24:05,535]\u001b[0m Trial 7 finished with value: 81.7071 and parameters: {'learning_rate': 0.00043178826427724864, 'max_depth': 5, 'num_boost_round': 5000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:25:58,488]\u001b[0m Trial 8 finished with value: 195.5675 and parameters: {'learning_rate': 0.00016214092143516427, 'max_depth': 10, 'num_boost_round': 2000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:26:26,154]\u001b[0m Trial 9 finished with value: 239.6618 and parameters: {'learning_rate': 0.000112097618717223, 'max_depth': 6, 'num_boost_round': 1000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:27:53,872]\u001b[0m Trial 10 finished with value: 47.2315 and parameters: {'learning_rate': 0.006836983741565353, 'max_depth': 4, 'num_boost_round': 5000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:29:22,140]\u001b[0m Trial 11 finished with value: 46.2447 and parameters: {'learning_rate': 0.00871587769999218, 'max_depth': 4, 'num_boost_round': 5000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:30:50,433]\u001b[0m Trial 12 finished with value: 46.1442 and parameters: {'learning_rate': 0.009084630877320926, 'max_depth': 4, 'num_boost_round': 5000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:32:41,069]\u001b[0m Trial 13 finished with value: 45.0998 and parameters: {'learning_rate': 0.003681464554750279, 'max_depth': 5, 'num_boost_round': 5000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:34:58,363]\u001b[0m Trial 14 finished with value: 43.4213 and parameters: {'learning_rate': 0.0032071074364811176, 'max_depth': 6, 'num_boost_round': 5000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:36:21,489]\u001b[0m Trial 15 finished with value: 44.3041 and parameters: {'learning_rate': 0.003384939276208599, 'max_depth': 6, 'num_boost_round': 3000}. Best is trial 1 with value: 43.3153.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:39:33,122]\u001b[0m Trial 16 finished with value: 42.3177 and parameters: {'learning_rate': 0.003142703908054338, 'max_depth': 8, 'num_boost_round': 5000}. Best is trial 16 with value: 42.3177.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:42:59,569]\u001b[0m Trial 17 finished with value: 43.2123 and parameters: {'learning_rate': 0.001099617953374696, 'max_depth': 8, 'num_boost_round': 5000}. Best is trial 16 with value: 42.3177.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:46:26,660]\u001b[0m Trial 18 finished with value: 43.3073 and parameters: {'learning_rate': 0.0010684223100444021, 'max_depth': 8, 'num_boost_round': 5000}. Best is trial 16 with value: 42.3177.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:49:11,550]\u001b[0m Trial 19 finished with value: 42.7982 and parameters: {'learning_rate': 0.0016310276898548752, 'max_depth': 8, 'num_boost_round': 4000}. Best is trial 16 with value: 42.3177.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:52:24,081]\u001b[0m Trial 20 finished with value: 42.9674 and parameters: {'learning_rate': 0.0018012942777466446, 'max_depth': 9, 'num_boost_round': 4000}. Best is trial 16 with value: 42.3177.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:55:36,706]\u001b[0m Trial 21 finished with value: 43.0153 and parameters: {'learning_rate': 0.001726646074785648, 'max_depth': 9, 'num_boost_round': 4000}. Best is trial 16 with value: 42.3177.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 17:58:53,512]\u001b[0m Trial 22 finished with value: 50.7244 and parameters: {'learning_rate': 0.0006802703694693366, 'max_depth': 9, 'num_boost_round': 4000}. Best is trial 16 with value: 42.3177.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:01:33,676]\u001b[0m Trial 23 finished with value: 42.5497 and parameters: {'learning_rate': 0.0020587489439921405, 'max_depth': 8, 'num_boost_round': 4000}. Best is trial 16 with value: 42.3177.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:04:06,045]\u001b[0m Trial 24 finished with value: 42.4244 and parameters: {'learning_rate': 0.0051644628619383695, 'max_depth': 8, 'num_boost_round': 4000}. Best is trial 16 with value: 42.3177.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:06:14,913]\u001b[0m Trial 25 finished with value: 42.2163 and parameters: {'learning_rate': 0.005897751040893953, 'max_depth': 7, 'num_boost_round': 4000}. Best is trial 25 with value: 42.2163.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:08:24,832]\u001b[0m Trial 26 finished with value: 42.2249 and parameters: {'learning_rate': 0.0053306654350362345, 'max_depth': 7, 'num_boost_round': 4000}. Best is trial 25 with value: 42.2163.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:10:02,430]\u001b[0m Trial 27 finished with value: 42.4149 and parameters: {'learning_rate': 0.005489132966571239, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 25 with value: 42.2163.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:11:09,546]\u001b[0m Trial 28 finished with value: 42.9686 and parameters: {'learning_rate': 0.004638279523066242, 'max_depth': 7, 'num_boost_round': 2000}. Best is trial 25 with value: 42.2163.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:12:19,525]\u001b[0m Trial 29 finished with value: 44.8125 and parameters: {'learning_rate': 0.0025699090480182834, 'max_depth': 7, 'num_boost_round': 2000}. Best is trial 25 with value: 42.2163.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:15:46,507]\u001b[0m Trial 30 finished with value: 44.0957 and parameters: {'learning_rate': 0.006664590198290471, 'max_depth': 10, 'num_boost_round': 4000}. Best is trial 25 with value: 42.2163.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:17:24,280]\u001b[0m Trial 31 finished with value: 42.4125 and parameters: {'learning_rate': 0.0051501802644826206, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 25 with value: 42.2163.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:19:00,407]\u001b[0m Trial 32 finished with value: 42.1909 and parameters: {'learning_rate': 0.009800443357306576, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 32 with value: 42.1909.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:20:37,492]\u001b[0m Trial 33 finished with value: 42.2939 and parameters: {'learning_rate': 0.009779853224650805, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 32 with value: 42.1909.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:21:58,284]\u001b[0m Trial 34 finished with value: 42.5955 and parameters: {'learning_rate': 0.009854816532301304, 'max_depth': 6, 'num_boost_round': 3000}. Best is trial 32 with value: 42.1909.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:23:35,948]\u001b[0m Trial 35 finished with value: 42.2307 and parameters: {'learning_rate': 0.007430745318198795, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 32 with value: 42.1909.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:24:42,609]\u001b[0m Trial 36 finished with value: 44.7522 and parameters: {'learning_rate': 0.006814414668053933, 'max_depth': 5, 'num_boost_round': 3000}. Best is trial 32 with value: 42.1909.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:26:22,230]\u001b[0m Trial 37 finished with value: 42.7448 and parameters: {'learning_rate': 0.004203399023900902, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 32 with value: 42.1909.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-08 18:27:59,176]\u001b[0m Trial 38 finished with value: 42.2876 and parameters: {'learning_rate': 0.006416749991473487, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 32 with value: 42.1909.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:28:27,577]\u001b[0m Trial 39 finished with value: 64.2987 and parameters: {'learning_rate': 0.0026085758322579294, 'max_depth': 6, 'num_boost_round': 1000}. Best is trial 32 with value: 42.1909.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:30:16,111]\u001b[0m Trial 40 finished with value: 42.4865 and parameters: {'learning_rate': 0.008189411921340458, 'max_depth': 6, 'num_boost_round': 4000}. Best is trial 32 with value: 42.1909.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:31:53,146]\u001b[0m Trial 41 finished with value: 42.1639 and parameters: {'learning_rate': 0.006809030784424057, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:33:29,966]\u001b[0m Trial 42 finished with value: 42.3007 and parameters: {'learning_rate': 0.007380600278838579, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:35:07,098]\u001b[0m Trial 43 finished with value: 42.4442 and parameters: {'learning_rate': 0.0056461037611297985, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:36:29,693]\u001b[0m Trial 44 finished with value: 43.7817 and parameters: {'learning_rate': 0.004340294786349315, 'max_depth': 6, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:37:03,426]\u001b[0m Trial 45 finished with value: 43.1639 and parameters: {'learning_rate': 0.007931587042436435, 'max_depth': 7, 'num_boost_round': 1000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:38:58,031]\u001b[0m Trial 46 finished with value: 42.3417 and parameters: {'learning_rate': 0.00605531030637175, 'max_depth': 8, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:40:05,989]\u001b[0m Trial 47 finished with value: 43.0328 and parameters: {'learning_rate': 0.004224817531539477, 'max_depth': 7, 'num_boost_round': 2000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:41:37,715]\u001b[0m Trial 48 finished with value: 104.227 and parameters: {'learning_rate': 0.0003816636110405872, 'max_depth': 5, 'num_boost_round': 4000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:42:59,102]\u001b[0m Trial 49 finished with value: 42.7591 and parameters: {'learning_rate': 0.008000830777726179, 'max_depth': 6, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:45:36,793]\u001b[0m Trial 50 finished with value: 42.4698 and parameters: {'learning_rate': 0.0028082781222434705, 'max_depth': 8, 'num_boost_round': 4000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:47:13,541]\u001b[0m Trial 51 finished with value: 42.2754 and parameters: {'learning_rate': 0.006972933109478037, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:48:53,691]\u001b[0m Trial 52 finished with value: 42.8211 and parameters: {'learning_rate': 0.003599260351285834, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:50:29,825]\u001b[0m Trial 53 finished with value: 42.2547 and parameters: {'learning_rate': 0.009983224562866613, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:52:07,306]\u001b[0m Trial 54 finished with value: 42.2155 and parameters: {'learning_rate': 0.007883891013734198, 'max_depth': 7, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:52:35,527]\u001b[0m Trial 55 finished with value: 45.087 and parameters: {'learning_rate': 0.008187341485866223, 'max_depth': 6, 'num_boost_round': 1000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:54:41,092]\u001b[0m Trial 56 finished with value: 57.5407 and parameters: {'learning_rate': 0.000788806147268509, 'max_depth': 8, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:56:29,654]\u001b[0m Trial 57 finished with value: 43.0488 and parameters: {'learning_rate': 0.004861812151134984, 'max_depth': 6, 'num_boost_round': 4000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 18:58:33,248]\u001b[0m Trial 58 finished with value: 123.8917 and parameters: {'learning_rate': 0.0003023683218360022, 'max_depth': 8, 'num_boost_round': 3000}. Best is trial 41 with value: 42.1639.\u001b[0m\n",
      "\u001b[32m[I 2022-03-08 19:00:22,537]\u001b[0m Trial 59 finished with value: 42.8184 and parameters: {'learning_rate': 0.005972933270396248, 'max_depth': 6, 'num_boost_round': 4000}. Best is trial 41 with value: 42.1639.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# launch Optuna Study\n",
    "\n",
    "study = optuna.create_study(study_name=STUDY_NAME, direction=\"minimize\")\n",
    "\n",
    "study.optimize(objective, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1803c5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.006809030784424057,\n",
       " 'max_depth': 7,\n",
       " 'num_boost_round': 3000}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7909246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_num_boost_round</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>42.1639</td>\n",
       "      <td>2022-03-08 18:30:16.112852</td>\n",
       "      <td>2022-03-08 18:31:53.146314</td>\n",
       "      <td>0 days 00:01:37.033462</td>\n",
       "      <td>0.006809</td>\n",
       "      <td>7</td>\n",
       "      <td>3000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>42.1909</td>\n",
       "      <td>2022-03-08 18:17:24.281973</td>\n",
       "      <td>2022-03-08 18:19:00.406822</td>\n",
       "      <td>0 days 00:01:36.124849</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>7</td>\n",
       "      <td>3000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>42.2155</td>\n",
       "      <td>2022-03-08 18:50:29.827178</td>\n",
       "      <td>2022-03-08 18:52:07.305875</td>\n",
       "      <td>0 days 00:01:37.478697</td>\n",
       "      <td>0.007884</td>\n",
       "      <td>7</td>\n",
       "      <td>3000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>42.2163</td>\n",
       "      <td>2022-03-08 18:04:06.046882</td>\n",
       "      <td>2022-03-08 18:06:14.912744</td>\n",
       "      <td>0 days 00:02:08.865862</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>7</td>\n",
       "      <td>4000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>42.2249</td>\n",
       "      <td>2022-03-08 18:06:14.914417</td>\n",
       "      <td>2022-03-08 18:08:24.832114</td>\n",
       "      <td>0 days 00:02:09.917697</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>7</td>\n",
       "      <td>4000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number    value             datetime_start          datetime_complete  \\\n",
       "41      41  42.1639 2022-03-08 18:30:16.112852 2022-03-08 18:31:53.146314   \n",
       "32      32  42.1909 2022-03-08 18:17:24.281973 2022-03-08 18:19:00.406822   \n",
       "54      54  42.2155 2022-03-08 18:50:29.827178 2022-03-08 18:52:07.305875   \n",
       "25      25  42.2163 2022-03-08 18:04:06.046882 2022-03-08 18:06:14.912744   \n",
       "26      26  42.2249 2022-03-08 18:06:14.914417 2022-03-08 18:08:24.832114   \n",
       "\n",
       "                 duration  params_learning_rate  params_max_depth  \\\n",
       "41 0 days 00:01:37.033462              0.006809                 7   \n",
       "32 0 days 00:01:36.124849              0.009800                 7   \n",
       "54 0 days 00:01:37.478697              0.007884                 7   \n",
       "25 0 days 00:02:08.865862              0.005898                 7   \n",
       "26 0 days 00:02:09.917697              0.005331                 7   \n",
       "\n",
       "    params_num_boost_round     state  \n",
       "41                    3000  COMPLETE  \n",
       "32                    3000  COMPLETE  \n",
       "54                    3000  COMPLETE  \n",
       "25                    4000  COMPLETE  \n",
       "26                    4000  COMPLETE  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize trials as an ordered Pandas df\n",
    "df = study.trials_dataframe()\n",
    "\n",
    "result_df = df[df[\"state\"] == \"COMPLETE\"].sort_values(by=[\"value\"], ascending=True)\n",
    "\n",
    "# best on top\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af88fa7d",
   "metadata": {},
   "source": [
    "### estimate RMSLE\n",
    "* it is the metric used in Kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e21101e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold: 1\n",
      "Processing fold: 2\n",
      "Processing fold: 3\n",
      "Processing fold: 4\n",
      "Processing fold: 5\n",
      "Processing fold: 6\n",
      "Processing fold: 7\n",
      "\n",
      "Avg. RMSLE: 0.405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make an estimation of rmsle on entire dataset\n",
    "\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "avg_rmsle = 0.0\n",
    "\n",
    "#\n",
    "# at each iteration you get a different set of indexes\n",
    "# from which you get different samples for train and validation dataset\n",
    "#\n",
    "for i, (train_idx, valid_idx) in enumerate(kf.split(data_used)):\n",
    "    print(\"Processing fold:\", i + 1)\n",
    "\n",
    "    # here we split the DataFrame, using the indexes for the fold\n",
    "    data_train = data_used.iloc[train_idx]\n",
    "    data_valid = data_used.iloc[valid_idx]\n",
    "\n",
    "    x_train = data_train[features].values\n",
    "    y_train = data_train[TARGET].values\n",
    "    x_valid = data_valid[features].values\n",
    "    y_valid = data_valid[TARGET].values\n",
    "\n",
    "    # it is important to pass explicitely n_estimators (only xgboost)\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=study.best_params[\"num_boost_round\"], **study.best_params\n",
    "    )\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_valid_preds = model.predict(x_valid)\n",
    "\n",
    "    # clip to zero (to avoid nan for rmsle)\n",
    "    y_valid_preds = np.where(y_valid_preds >= 0, y_valid_preds, 0)\n",
    "\n",
    "    avg_rmsle += rmsle(y_valid_preds, y_valid) / float(FOLDS)\n",
    "\n",
    "print()\n",
    "print(\"Avg. RMSLE:\", round(avg_rmsle, 4))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7560dee1",
   "metadata": {},
   "source": [
    "### Train the model on entire train set and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34db5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.2 s, sys: 87.9 ms, total: 52.3 s\n",
      "Wall time: 14.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.006809030784424057,\n",
       "             max_delta_step=0, max_depth=7, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=3000, n_jobs=4,\n",
       "             num_boost_round=3000, num_parallel_tree=1, predictor='auto',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             subsample=1, tree_method='exact', validate_parameters=1,\n",
       "             verbosity=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=study.best_params[\"num_boost_round\"], **study.best_params\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "260abe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"xgboost.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5be28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
