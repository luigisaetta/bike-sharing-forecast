{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa826f87",
   "metadata": {},
   "source": [
    "### Tuning HP: XGBoost and Optuna\n",
    "* adopting sklearn cross validate\n",
    "* using rmsle as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b02034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# the GBM used\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# to encode categoricals\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# see utils.py\n",
    "from utils import add_features, rmsle, train_encoders, apply_encoders\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8915e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "\n",
    "FILE_TRAIN = \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce1f6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "data_orig = pd.read_csv(FILE_TRAIN)\n",
    "\n",
    "#\n",
    "# Data preparation, feature engineering\n",
    "#\n",
    "\n",
    "# add features (hour, year) extracted form timestamp\n",
    "data_extended = add_features(data_orig)\n",
    "\n",
    "# ok, we will treat as categorical: holiday, hour, season, weather, workingday, year\n",
    "all_columns = data_extended.columns\n",
    "\n",
    "# cols to be ignored\n",
    "# atemp and temp are strongly correlated (0.98) we're taking only one (atemp)\n",
    "del_columns = [\"datetime\", \"casual\", \"registered\", \"temp\"]\n",
    "\n",
    "TARGET = \"count\"\n",
    "cat_cols = [\"season\", \"holiday\", \"workingday\", \"weather\", \"hour\", \"year\"]\n",
    "num_cols = list(set(all_columns) - set([TARGET]) - set(del_columns) - set(cat_cols))\n",
    "features = sorted(cat_cols + num_cols)\n",
    "\n",
    "# drop ignored columns\n",
    "data_used = data_extended.drop(del_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad0f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train for coding: season \n",
      "train for coding: weather \n",
      "train for coding: year \n",
      "\n",
      "Coding: season \n",
      "Coding: weather \n",
      "Coding: year \n"
     ]
    }
   ],
   "source": [
    "# Code categorical columns (only season, weather, year)\n",
    "le_list = train_encoders(data_used)\n",
    "\n",
    "# coding\n",
    "data_used = apply_encoders(data_used, le_list)\n",
    "\n",
    "# reorder columns, move count at the end\n",
    "data_used = data_used[features + [TARGET]]\n",
    "\n",
    "# define indexes for cat_cols\n",
    "# not using now, but can be useful in future\n",
    "cat_columns_idxs = [i for i, col in enumerate(features) if col in cat_cols]\n",
    "\n",
    "# finally we have the train dataset\n",
    "X = data_used[features].values\n",
    "y = data_used[TARGET].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212183d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the HPO session with Optuna\n",
    "FOLDS = 7\n",
    "SEED = 4321\n",
    "\n",
    "N_TRIALS = 60\n",
    "STUDY_NAME = \"gbm11\"\n",
    "\n",
    "# ranges\n",
    "LR_LOW = 1e-4\n",
    "LR_HIGH = 1e-2\n",
    "DEPTH_LOW = 5\n",
    "DEPTH_HIGH = 10\n",
    "N_ITER_LIST = [3000, 3500, 4000, 4500, 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b66070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here we define what we do using Optuna\n",
    "#\n",
    "def objective(trial):\n",
    "\n",
    "    # tuning on these parameters\n",
    "    # names are implementation (diff for xg etc)\n",
    "    dict_params = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"learning_rate\": trial.suggest_loguniform(\n",
    "            \"learning_rate\", low=LR_LOW, high=LR_HIGH\n",
    "        ),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", DEPTH_LOW, DEPTH_HIGH),\n",
    "        \"num_boost_round\": trial.suggest_categorical(\"num_boost_round\", N_ITER_LIST),\n",
    "    }\n",
    "\n",
    "    # for XGBoost seems I have to pass esplicitely n_estimators\n",
    "    regr = xgb.XGBRegressor(n_estimators=dict_params[\"num_boost_round\"], **dict_params)\n",
    "\n",
    "    # using rmsle for scoring\n",
    "    # greater is better is Flase because it is an error measure\n",
    "    # then make_scorer sign-flip and therefore we will maximize it to get the best\n",
    "    scorer = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "    scores = cross_validate(regr, X, y, cv=FOLDS, scoring=scorer)\n",
    "\n",
    "    avg_test_score = round(np.mean(scores[\"test_score\"]), 4)\n",
    "\n",
    "    return avg_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeec9af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-09 16:03:31,972]\u001b[0m A new study created in memory with name: gbm11\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:06:05,743]\u001b[0m Trial 0 finished with value: -0.7384 and parameters: {'learning_rate': 0.00017483394431969703, 'max_depth': 7, 'num_boost_round': 4000}. Best is trial 0 with value: -0.7384.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:13:27,303]\u001b[0m Trial 1 finished with value: -0.4375 and parameters: {'learning_rate': 0.0006730970747687033, 'max_depth': 10, 'num_boost_round': 5000}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:14:58,749]\u001b[0m Trial 2 finished with value: -0.559 and parameters: {'learning_rate': 0.00043372976049416845, 'max_depth': 5, 'num_boost_round': 4000}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:16:05,301]\u001b[0m Trial 3 finished with value: -0.9 and parameters: {'learning_rate': 0.00017359027407523402, 'max_depth': 5, 'num_boost_round': 3000}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:19:48,797]\u001b[0m Trial 4 finished with value: -0.5325 and parameters: {'learning_rate': 0.004439482189514644, 'max_depth': 8, 'num_boost_round': 5000}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:25:16,442]\u001b[0m Trial 5 finished with value: -0.4589 and parameters: {'learning_rate': 0.0020276007031123974, 'max_depth': 10, 'num_boost_round': 4000}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:28:33,002]\u001b[0m Trial 6 finished with value: -0.4438 and parameters: {'learning_rate': 0.0005087761494168258, 'max_depth': 7, 'num_boost_round': 5000}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:33:39,403]\u001b[0m Trial 7 finished with value: -0.4463 and parameters: {'learning_rate': 0.0015960107470807479, 'max_depth': 10, 'num_boost_round': 3500}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:37:27,786]\u001b[0m Trial 8 finished with value: -0.4626 and parameters: {'learning_rate': 0.00118206614654061, 'max_depth': 8, 'num_boost_round': 4500}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:38:36,499]\u001b[0m Trial 9 finished with value: -0.5774 and parameters: {'learning_rate': 0.0005073744996752412, 'max_depth': 5, 'num_boost_round': 3000}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:43:19,157]\u001b[0m Trial 10 finished with value: -0.5226 and parameters: {'learning_rate': 0.009364618560370153, 'max_depth': 9, 'num_boost_round': 5000}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:46:36,012]\u001b[0m Trial 11 finished with value: -0.4441 and parameters: {'learning_rate': 0.0005067375797585176, 'max_depth': 7, 'num_boost_round': 5000}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:49:06,413]\u001b[0m Trial 12 finished with value: -0.5205 and parameters: {'learning_rate': 0.0003285444729078427, 'max_depth': 6, 'num_boost_round': 5000}. Best is trial 1 with value: -0.4375.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:54:44,790]\u001b[0m Trial 13 finished with value: -0.431 and parameters: {'learning_rate': 0.0007958084099473359, 'max_depth': 9, 'num_boost_round': 5000}. Best is trial 13 with value: -0.431.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 16:59:15,186]\u001b[0m Trial 14 finished with value: -0.4704 and parameters: {'learning_rate': 0.0025657310097100656, 'max_depth': 9, 'num_boost_round': 4500}. Best is trial 13 with value: -0.431.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:03:10,299]\u001b[0m Trial 15 finished with value: -0.4317 and parameters: {'learning_rate': 0.0008047903453944017, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 13 with value: -0.431.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:07:05,585]\u001b[0m Trial 16 finished with value: -0.4309 and parameters: {'learning_rate': 0.0008863636267615406, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:10:45,538]\u001b[0m Trial 17 finished with value: -1.1156 and parameters: {'learning_rate': 0.00010598344648323021, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:13:28,524]\u001b[0m Trial 18 finished with value: -0.4954 and parameters: {'learning_rate': 0.003511471143452391, 'max_depth': 8, 'num_boost_round': 3500}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:17:25,994]\u001b[0m Trial 19 finished with value: -0.4349 and parameters: {'learning_rate': 0.0013663800851806472, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:23:33,657]\u001b[0m Trial 20 finished with value: -0.5645 and parameters: {'learning_rate': 0.00024131233443971107, 'max_depth': 10, 'num_boost_round': 4500}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:27:28,751]\u001b[0m Trial 21 finished with value: -0.4318 and parameters: {'learning_rate': 0.0007943231484562331, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:30:29,337]\u001b[0m Trial 22 finished with value: -0.4498 and parameters: {'learning_rate': 0.000981459069275565, 'max_depth': 8, 'num_boost_round': 3500}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:34:25,317]\u001b[0m Trial 23 finished with value: -0.4316 and parameters: {'learning_rate': 0.0008190254157931059, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:37:26,001]\u001b[0m Trial 24 finished with value: -0.453 and parameters: {'learning_rate': 0.0011308147226816714, 'max_depth': 8, 'num_boost_round': 3500}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:41:47,924]\u001b[0m Trial 25 finished with value: -0.4479 and parameters: {'learning_rate': 0.0018979261194608517, 'max_depth': 10, 'num_boost_round': 3000}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:45:33,646]\u001b[0m Trial 26 finished with value: -0.5582 and parameters: {'learning_rate': 0.00030671228381171464, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:49:28,966]\u001b[0m Trial 27 finished with value: -0.4323 and parameters: {'learning_rate': 0.0007511069961522947, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:53:18,001]\u001b[0m Trial 28 finished with value: -0.5068 and parameters: {'learning_rate': 0.003174750282605511, 'max_depth': 8, 'num_boost_round': 5000}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:55:11,127]\u001b[0m Trial 29 finished with value: -0.5722 and parameters: {'learning_rate': 0.005246101121143706, 'max_depth': 6, 'num_boost_round': 4000}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 17:59:26,356]\u001b[0m Trial 30 finished with value: -0.4535 and parameters: {'learning_rate': 0.0006404707038094409, 'max_depth': 10, 'num_boost_round': 3000}. Best is trial 16 with value: -0.4309.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:03:22,582]\u001b[0m Trial 31 finished with value: -0.4307 and parameters: {'learning_rate': 0.0009126590966928525, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:07:18,272]\u001b[0m Trial 32 finished with value: -0.4309 and parameters: {'learning_rate': 0.0009655168407755203, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:12:25,866]\u001b[0m Trial 33 finished with value: -0.4432 and parameters: {'learning_rate': 0.0014815705024157813, 'max_depth': 10, 'num_boost_round': 3500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:16:56,394]\u001b[0m Trial 34 finished with value: -0.431 and parameters: {'learning_rate': 0.000981439936968354, 'max_depth': 9, 'num_boost_round': 4000}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:19:52,960]\u001b[0m Trial 35 finished with value: -0.5059 and parameters: {'learning_rate': 0.0003808621179951785, 'max_depth': 8, 'num_boost_round': 3500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:25:47,130]\u001b[0m Trial 36 finished with value: -0.4411 and parameters: {'learning_rate': 0.0010385736712913115, 'max_depth': 10, 'num_boost_round': 4000}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:29:00,832]\u001b[0m Trial 37 finished with value: -0.482 and parameters: {'learning_rate': 0.002015216883025111, 'max_depth': 8, 'num_boost_round': 4000}. Best is trial 31 with value: -0.4307.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-09 18:31:37,123]\u001b[0m Trial 38 finished with value: -0.4523 and parameters: {'learning_rate': 0.0005647953100866222, 'max_depth': 7, 'num_boost_round': 4000}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:36:59,973]\u001b[0m Trial 39 finished with value: -0.5775 and parameters: {'learning_rate': 0.00020223997390042688, 'max_depth': 9, 'num_boost_round': 5000}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:42:54,581]\u001b[0m Trial 40 finished with value: -0.4425 and parameters: {'learning_rate': 0.001189778478476448, 'max_depth': 10, 'num_boost_round': 4000}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:47:20,994]\u001b[0m Trial 41 finished with value: -0.4336 and parameters: {'learning_rate': 0.0006193339528976119, 'max_depth': 9, 'num_boost_round': 4000}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:52:23,789]\u001b[0m Trial 42 finished with value: -0.4315 and parameters: {'learning_rate': 0.000914031222929688, 'max_depth': 9, 'num_boost_round': 4500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 18:56:24,406]\u001b[0m Trial 43 finished with value: -0.4841 and parameters: {'learning_rate': 0.001751559957045985, 'max_depth': 8, 'num_boost_round': 5000}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:00:13,603]\u001b[0m Trial 44 finished with value: -0.4731 and parameters: {'learning_rate': 0.00044205305235132865, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:04:36,848]\u001b[0m Trial 45 finished with value: -0.4409 and parameters: {'learning_rate': 0.0013840397705866972, 'max_depth': 10, 'num_boost_round': 3000}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:09:33,559]\u001b[0m Trial 46 finished with value: -0.4681 and parameters: {'learning_rate': 0.0024160963027553555, 'max_depth': 9, 'num_boost_round': 5000}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:12:32,548]\u001b[0m Trial 47 finished with value: -0.451 and parameters: {'learning_rate': 0.000688595127565893, 'max_depth': 8, 'num_boost_round': 3500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:16:55,690]\u001b[0m Trial 48 finished with value: -0.4574 and parameters: {'learning_rate': 0.0004349308569642051, 'max_depth': 9, 'num_boost_round': 4000}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:24:16,851]\u001b[0m Trial 49 finished with value: -0.4491 and parameters: {'learning_rate': 0.0012234982794237577, 'max_depth': 10, 'num_boost_round': 5000}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:29:20,603]\u001b[0m Trial 50 finished with value: -0.4337 and parameters: {'learning_rate': 0.0010048251828175694, 'max_depth': 9, 'num_boost_round': 4500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:34:25,120]\u001b[0m Trial 51 finished with value: -0.4314 and parameters: {'learning_rate': 0.0008730163743294052, 'max_depth': 9, 'num_boost_round': 4500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:39:29,304]\u001b[0m Trial 52 finished with value: -0.4312 and parameters: {'learning_rate': 0.0008920133833054551, 'max_depth': 9, 'num_boost_round': 4500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:44:30,770]\u001b[0m Trial 53 finished with value: -0.4334 and parameters: {'learning_rate': 0.0005544996537936689, 'max_depth': 9, 'num_boost_round': 4500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:49:21,329]\u001b[0m Trial 54 finished with value: -0.4538 and parameters: {'learning_rate': 0.0015983809040935931, 'max_depth': 9, 'num_boost_round': 4500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:52:19,362]\u001b[0m Trial 55 finished with value: -0.4507 and parameters: {'learning_rate': 0.0007071183283045417, 'max_depth': 8, 'num_boost_round': 3500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:54:03,987]\u001b[0m Trial 56 finished with value: -0.5088 and parameters: {'learning_rate': 0.0012585410433727225, 'max_depth': 6, 'num_boost_round': 3500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 19:59:07,759]\u001b[0m Trial 57 finished with value: -0.4313 and parameters: {'learning_rate': 0.0009159159048036353, 'max_depth': 9, 'num_boost_round': 4500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:02:55,893]\u001b[0m Trial 58 finished with value: -0.5088 and parameters: {'learning_rate': 0.0003682390871205569, 'max_depth': 9, 'num_boost_round': 3500}. Best is trial 31 with value: -0.4307.\u001b[0m\n",
      "\u001b[32m[I 2022-03-09 20:10:14,496]\u001b[0m Trial 59 finished with value: -0.4405 and parameters: {'learning_rate': 0.0004891616014272796, 'max_depth': 10, 'num_boost_round': 5000}. Best is trial 31 with value: -0.4307.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# launch Optuna Study\n",
    "\n",
    "study = optuna.create_study(study_name=STUDY_NAME, direction=\"maximize\")\n",
    "\n",
    "study.optimize(objective, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1803c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are:\n",
      "{'learning_rate': 0.0009126590966928525, 'max_depth': 9, 'num_boost_round': 3500}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters are:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7909246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_num_boost_round</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>-0.4307</td>\n",
       "      <td>2022-03-09 17:59:26.357293</td>\n",
       "      <td>2022-03-09 18:03:22.582281</td>\n",
       "      <td>0 days 00:03:56.224988</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>9</td>\n",
       "      <td>3500</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.4309</td>\n",
       "      <td>2022-03-09 17:03:10.300362</td>\n",
       "      <td>2022-03-09 17:07:05.585218</td>\n",
       "      <td>0 days 00:03:55.284856</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>9</td>\n",
       "      <td>3500</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>-0.4309</td>\n",
       "      <td>2022-03-09 18:03:22.583823</td>\n",
       "      <td>2022-03-09 18:07:18.272377</td>\n",
       "      <td>0 days 00:03:55.688554</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>9</td>\n",
       "      <td>3500</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.4310</td>\n",
       "      <td>2022-03-09 18:12:25.867916</td>\n",
       "      <td>2022-03-09 18:16:56.393726</td>\n",
       "      <td>0 days 00:04:30.525810</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>9</td>\n",
       "      <td>4000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.4310</td>\n",
       "      <td>2022-03-09 16:49:06.414481</td>\n",
       "      <td>2022-03-09 16:54:44.789990</td>\n",
       "      <td>0 days 00:05:38.375509</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>9</td>\n",
       "      <td>5000</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>-0.4312</td>\n",
       "      <td>2022-03-09 19:34:25.122212</td>\n",
       "      <td>2022-03-09 19:39:29.304546</td>\n",
       "      <td>0 days 00:05:04.182334</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>9</td>\n",
       "      <td>4500</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>-0.4313</td>\n",
       "      <td>2022-03-09 19:54:03.989067</td>\n",
       "      <td>2022-03-09 19:59:07.758679</td>\n",
       "      <td>0 days 00:05:03.769612</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>9</td>\n",
       "      <td>4500</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>-0.4314</td>\n",
       "      <td>2022-03-09 19:29:20.605063</td>\n",
       "      <td>2022-03-09 19:34:25.120570</td>\n",
       "      <td>0 days 00:05:04.515507</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>9</td>\n",
       "      <td>4500</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>-0.4315</td>\n",
       "      <td>2022-03-09 18:47:20.995977</td>\n",
       "      <td>2022-03-09 18:52:23.789363</td>\n",
       "      <td>0 days 00:05:02.793386</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>9</td>\n",
       "      <td>4500</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.4316</td>\n",
       "      <td>2022-03-09 17:30:29.338657</td>\n",
       "      <td>2022-03-09 17:34:25.317643</td>\n",
       "      <td>0 days 00:03:55.978986</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>9</td>\n",
       "      <td>3500</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number   value             datetime_start          datetime_complete  \\\n",
       "31      31 -0.4307 2022-03-09 17:59:26.357293 2022-03-09 18:03:22.582281   \n",
       "16      16 -0.4309 2022-03-09 17:03:10.300362 2022-03-09 17:07:05.585218   \n",
       "32      32 -0.4309 2022-03-09 18:03:22.583823 2022-03-09 18:07:18.272377   \n",
       "34      34 -0.4310 2022-03-09 18:12:25.867916 2022-03-09 18:16:56.393726   \n",
       "13      13 -0.4310 2022-03-09 16:49:06.414481 2022-03-09 16:54:44.789990   \n",
       "52      52 -0.4312 2022-03-09 19:34:25.122212 2022-03-09 19:39:29.304546   \n",
       "57      57 -0.4313 2022-03-09 19:54:03.989067 2022-03-09 19:59:07.758679   \n",
       "51      51 -0.4314 2022-03-09 19:29:20.605063 2022-03-09 19:34:25.120570   \n",
       "42      42 -0.4315 2022-03-09 18:47:20.995977 2022-03-09 18:52:23.789363   \n",
       "23      23 -0.4316 2022-03-09 17:30:29.338657 2022-03-09 17:34:25.317643   \n",
       "\n",
       "                 duration  params_learning_rate  params_max_depth  \\\n",
       "31 0 days 00:03:56.224988              0.000913                 9   \n",
       "16 0 days 00:03:55.284856              0.000886                 9   \n",
       "32 0 days 00:03:55.688554              0.000966                 9   \n",
       "34 0 days 00:04:30.525810              0.000981                 9   \n",
       "13 0 days 00:05:38.375509              0.000796                 9   \n",
       "52 0 days 00:05:04.182334              0.000892                 9   \n",
       "57 0 days 00:05:03.769612              0.000916                 9   \n",
       "51 0 days 00:05:04.515507              0.000873                 9   \n",
       "42 0 days 00:05:02.793386              0.000914                 9   \n",
       "23 0 days 00:03:55.978986              0.000819                 9   \n",
       "\n",
       "    params_num_boost_round     state  \n",
       "31                    3500  COMPLETE  \n",
       "16                    3500  COMPLETE  \n",
       "32                    3500  COMPLETE  \n",
       "34                    4000  COMPLETE  \n",
       "13                    5000  COMPLETE  \n",
       "52                    4500  COMPLETE  \n",
       "57                    4500  COMPLETE  \n",
       "51                    4500  COMPLETE  \n",
       "42                    4500  COMPLETE  \n",
       "23                    3500  COMPLETE  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize trials as an ordered Pandas df\n",
    "df = study.trials_dataframe()\n",
    "\n",
    "result_df = df[df[\"state\"] == \"COMPLETE\"].sort_values(by=[\"value\"], ascending=False)\n",
    "\n",
    "# best on top\n",
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7560dee1",
   "metadata": {},
   "source": [
    "### Train the model with best params on train set and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34db5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 58s, sys: 284 ms, total: 1min 58s\n",
      "Wall time: 37.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.0009126590966928525,\n",
       "             max_delta_step=0, max_depth=9, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=3500, n_jobs=4,\n",
       "             num_boost_round=3500, num_parallel_tree=1, predictor='auto',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             subsample=1, tree_method='exact', validate_parameters=1,\n",
       "             verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=study.best_params[\"num_boost_round\"], **study.best_params\n",
    ")\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "260abe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"xgboost.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5be28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
